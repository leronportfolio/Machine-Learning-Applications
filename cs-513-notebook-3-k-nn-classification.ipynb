{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc536590",
   "metadata": {
    "papermill": {
     "duration": 0.012807,
     "end_time": "2023-04-21T21:40:05.484347",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.471540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains two parts. **Part 1, Evaluating k-NN Classifiers**, provides you an opportunity to demonstrate your ability to apply course concepts to determine the ideal **_k_** for a k-NN Classifier on a contrived Iris data set. **Part 2, Classifying Handwritten Digits**, provides you an opportunity to practice using widely-used ML libraries and an ML workflow to solve a classification problem.\n",
    "\n",
    "You do not need to complete Part 1 in order to complete Part 2. If you get stuck on Part 1, and choose to work on Part 2, be sure that all of your code for Part 1 runs without error. You can comment out your code in Part 1 if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2bc48c",
   "metadata": {
    "papermill": {
     "duration": 0.011327,
     "end_time": "2023-04-21T21:40:05.507094",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.495767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 1: Evaluating k-NN Classifiers\n",
    "\n",
    "Given a simple KnnClassifier, and a complete data set of [Iris attributes](https://www.kaggle.com/datasets/uciml/iris), demonstrate your ability to:\n",
    "\n",
    "1. Split a data set into appropriate training and test sets\n",
    "2. \"Train\" a k-NN classifier\n",
    "3. Repeatedly test a k-NN classifier, and collect generalization errors\n",
    "4. Analyze the generalization error for different values of `k`\n",
    "5. Identify the ideal `k` value for this classifier\n",
    "\n",
    "## The Classifier Implementation\n",
    "\n",
    "Let's first introduce the classifier, which you should find familiar, and you do not need to modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c161ea",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:05.533556Z",
     "iopub.status.busy": "2023-04-21T21:40:05.532987Z",
     "iopub.status.idle": "2023-04-21T21:40:05.551825Z",
     "shell.execute_reply": "2023-04-21T21:40:05.550679Z"
    },
    "papermill": {
     "duration": 0.035554,
     "end_time": "2023-04-21T21:40:05.554695",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.519141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A simple KnnClassifier. Uses Euclidean distance.\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "class KnnClassifier:\n",
    "\n",
    "    def __init__(self, k = 1):\n",
    "        self.k = k\n",
    "\n",
    "    def train(self, training_set):\n",
    "        self.training_set = training_set\n",
    "\n",
    "    def test(self, test_set):\n",
    "        number_of_correct_predictions = 0\n",
    "        for example in test_set:\n",
    "            prediction = self.predict(example[:-1])\n",
    "            if prediction == example[-1]:\n",
    "                number_of_correct_predictions += 1\n",
    "        return number_of_correct_predictions / len(test_set)\n",
    "\n",
    "    def predict(self, x):\n",
    "        distances = {}\n",
    "        for training_instance in self.training_set:\n",
    "            distance = self._distance(training_instance[:-1], x)\n",
    "            distances[distance] = training_instance[-1]\n",
    "        k_nearest_keys = sorted(list(distances.keys()))[:self.k]\n",
    "        k_nearest_labels = [distances[key] for key in k_nearest_keys]\n",
    "        label_frequencies = {label:k_nearest_labels.count(label) for label in k_nearest_labels}\n",
    "        frequencies = list(label_frequencies.values())\n",
    "        labels = list(label_frequencies.keys())\n",
    "        return labels[frequencies.index(max(frequencies))]\n",
    "\n",
    "    def _distance(self, training_instance, x):\n",
    "        sum_of_squares = 0\n",
    "        for i in range(len(x)):\n",
    "            sum_of_squares += (x[i] - training_instance[i])**2\n",
    "        return \"%.5f\" % sqrt(sum_of_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b9a91b",
   "metadata": {
    "papermill": {
     "duration": 0.012789,
     "end_time": "2023-04-21T21:40:05.579402",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.566613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Data Set\n",
    "\n",
    "There is no need for you to manually load the data set. We have provided the classic Iris data set here as a two-dimensional Python list, where each sub-list represents the attributes for one flower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c9ae62",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:05.604907Z",
     "iopub.status.busy": "2023-04-21T21:40:05.603998Z",
     "iopub.status.idle": "2023-04-21T21:40:05.640936Z",
     "shell.execute_reply": "2023-04-21T21:40:05.639690Z"
    },
    "papermill": {
     "duration": 0.053263,
     "end_time": "2023-04-21T21:40:05.643926",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.590663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris_data_set = [\n",
    "    [5.1,3.5,1.4,0.2,'Iris-setosa'],\n",
    "    [4.9,3.0,1.4,0.2,'Iris-setosa'],\n",
    "    [4.7,3.2,1.3,0.2,'Iris-setosa'],\n",
    "    [4.6,3.1,1.5,0.2,'Iris-setosa'],\n",
    "    [5.0,3.6,1.4,0.2,'Iris-setosa'],\n",
    "    [5.4,3.9,1.7,0.4,'Iris-setosa'],\n",
    "    [4.6,3.4,1.4,0.3,'Iris-setosa'],\n",
    "    [5.0,3.4,1.5,0.2,'Iris-setosa'],\n",
    "    [4.4,2.9,1.4,0.2,'Iris-setosa'],\n",
    "    [4.9,3.1,1.5,0.1,'Iris-setosa'],\n",
    "    [5.4,3.7,1.5,0.2,'Iris-setosa'],\n",
    "    [4.8,3.4,1.6,0.2,'Iris-setosa'],\n",
    "    [4.8,3.0,1.4,0.1,'Iris-setosa'],\n",
    "    [4.3,3.0,1.1,0.1,'Iris-setosa'],\n",
    "    [5.8,4.0,1.2,0.2,'Iris-setosa'],\n",
    "    [5.7,4.4,1.5,0.4,'Iris-setosa'],\n",
    "    [5.4,3.9,1.3,0.4,'Iris-setosa'],\n",
    "    [5.1,3.5,1.4,0.3,'Iris-setosa'],\n",
    "    [5.7,3.8,1.7,0.3,'Iris-setosa'],\n",
    "    [5.1,3.8,1.5,0.3,'Iris-setosa'],\n",
    "    [5.4,3.4,1.7,0.2,'Iris-setosa'],\n",
    "    [5.1,3.7,1.5,0.4,'Iris-setosa'],\n",
    "    [4.6,3.6,1.0,0.2,'Iris-setosa'],\n",
    "    [5.1,3.3,1.7,0.5,'Iris-setosa'],\n",
    "    [4.8,3.4,1.9,0.2,'Iris-setosa'],\n",
    "    [5.0,3.0,1.6,0.2,'Iris-setosa'],\n",
    "    [5.0,3.4,1.6,0.4,'Iris-setosa'],\n",
    "    [5.2,3.5,1.5,0.2,'Iris-setosa'],\n",
    "    [5.2,3.4,1.4,0.2,'Iris-setosa'],\n",
    "    [4.7,3.2,1.6,0.2,'Iris-setosa'],\n",
    "    [4.8,3.1,1.6,0.2,'Iris-setosa'],\n",
    "    [5.4,3.4,1.5,0.4,'Iris-setosa'],\n",
    "    [5.2,4.1,1.5,0.1,'Iris-setosa'],\n",
    "    [5.5,4.2,1.4,0.2,'Iris-setosa'],\n",
    "    [4.9,3.1,1.5,0.1,'Iris-setosa'],\n",
    "    [5.0,3.2,1.2,0.2,'Iris-setosa'],\n",
    "    [5.5,3.5,1.3,0.2,'Iris-setosa'],\n",
    "    [4.9,3.1,1.5,0.1,'Iris-setosa'],\n",
    "    [4.4,3.0,1.3,0.2,'Iris-setosa'],\n",
    "    [5.1,3.4,1.5,0.2,'Iris-setosa'],\n",
    "    [5.0,3.5,1.3,0.3,'Iris-setosa'],\n",
    "    [4.5,2.3,1.3,0.3,'Iris-setosa'],\n",
    "    [4.4,3.2,1.3,0.2,'Iris-setosa'],\n",
    "    [5.0,3.5,1.6,0.6,'Iris-setosa'],\n",
    "    [5.1,3.8,1.9,0.4,'Iris-setosa'],\n",
    "    [4.8,3.0,1.4,0.3,'Iris-setosa'],\n",
    "    [5.1,3.8,1.6,0.2,'Iris-setosa'],\n",
    "    [4.6,3.2,1.4,0.2,'Iris-setosa'],\n",
    "    [5.3,3.7,1.5,0.2,'Iris-setosa'],\n",
    "    [5.0,3.3,1.4,0.2,'Iris-setosa'],\n",
    "    [7.0,3.2,4.7,1.4,'Iris-versicolor'],\n",
    "    [6.4,3.2,4.5,1.5,'Iris-versicolor'],\n",
    "    [6.9,3.1,4.9,1.5,'Iris-versicolor'],\n",
    "    [5.5,2.3,4.0,1.3,'Iris-versicolor'],\n",
    "    [6.5,2.8,4.6,1.5,'Iris-versicolor'],\n",
    "    [5.7,2.8,4.5,1.3,'Iris-versicolor'],\n",
    "    [6.3,3.3,4.7,1.6,'Iris-versicolor'],\n",
    "    [4.9,2.4,3.3,1.0,'Iris-versicolor'],\n",
    "    [6.6,2.9,4.6,1.3,'Iris-versicolor'],\n",
    "    [5.2,2.7,3.9,1.4,'Iris-versicolor'],\n",
    "    [5.0,2.0,3.5,1.0,'Iris-versicolor'],\n",
    "    [5.9,3.0,4.2,1.5,'Iris-versicolor'],\n",
    "    [6.0,2.2,4.0,1.0,'Iris-versicolor'],\n",
    "    [6.1,2.9,4.7,1.4,'Iris-versicolor'],\n",
    "    [5.6,2.9,3.6,1.3,'Iris-versicolor'],\n",
    "    [6.7,3.1,4.4,1.4,'Iris-versicolor'],\n",
    "    [5.6,3.0,4.5,1.5,'Iris-versicolor'],\n",
    "    [5.8,2.7,4.1,1.0,'Iris-versicolor'],\n",
    "    [6.2,2.2,4.5,1.5,'Iris-versicolor'],\n",
    "    [5.6,2.5,3.9,1.1,'Iris-versicolor'],\n",
    "    [5.9,3.2,4.8,1.8,'Iris-versicolor'],\n",
    "    [6.1,2.8,4.0,1.3,'Iris-versicolor'],\n",
    "    [6.3,2.5,4.9,1.5,'Iris-versicolor'],\n",
    "    [6.1,2.8,4.7,1.2,'Iris-versicolor'],\n",
    "    [6.4,2.9,4.3,1.3,'Iris-versicolor'],\n",
    "    [6.6,3.0,4.4,1.4,'Iris-versicolor'],\n",
    "    [6.8,2.8,4.8,1.4,'Iris-versicolor'],\n",
    "    [6.7,3.0,5.0,1.7,'Iris-versicolor'],\n",
    "    [6.0,2.9,4.5,1.5,'Iris-versicolor'],\n",
    "    [5.7,2.6,3.5,1.0,'Iris-versicolor'],\n",
    "    [5.5,2.4,3.8,1.1,'Iris-versicolor'],\n",
    "    [5.5,2.4,3.7,1.0,'Iris-versicolor'],\n",
    "    [5.8,2.7,3.9,1.2,'Iris-versicolor'],\n",
    "    [6.0,2.7,5.1,1.6,'Iris-versicolor'],\n",
    "    [5.4,3.0,4.5,1.5,'Iris-versicolor'],\n",
    "    [6.0,3.4,4.5,1.6,'Iris-versicolor'],\n",
    "    [6.7,3.1,4.7,1.5,'Iris-versicolor'],\n",
    "    [6.3,2.3,4.4,1.3,'Iris-versicolor'],\n",
    "    [5.6,3.0,4.1,1.3,'Iris-versicolor'],\n",
    "    [5.5,2.5,4.0,1.3,'Iris-versicolor'],\n",
    "    [5.5,2.6,4.4,1.2,'Iris-versicolor'],\n",
    "    [6.1,3.0,4.6,1.4,'Iris-versicolor'],\n",
    "    [5.8,2.6,4.0,1.2,'Iris-versicolor'],\n",
    "    [5.0,2.3,3.3,1.0,'Iris-versicolor'],\n",
    "    [5.6,2.7,4.2,1.3,'Iris-versicolor'],\n",
    "    [5.7,3.0,4.2,1.2,'Iris-versicolor'],\n",
    "    [5.7,2.9,4.2,1.3,'Iris-versicolor'],\n",
    "    [6.2,2.9,4.3,1.3,'Iris-versicolor'],\n",
    "    [5.1,2.5,3.0,1.1,'Iris-versicolor'],\n",
    "    [5.7,2.8,4.1,1.3,'Iris-versicolor'],\n",
    "    [6.3,3.3,6.0,2.5,'Iris-virginica'],\n",
    "    [5.8,2.7,5.1,1.9,'Iris-virginica'],\n",
    "    [7.1,3.0,5.9,2.1,'Iris-virginica'],\n",
    "    [6.3,2.9,5.6,1.8,'Iris-virginica'],\n",
    "    [6.5,3.0,5.8,2.2,'Iris-virginica'],\n",
    "    [7.6,3.0,6.6,2.1,'Iris-virginica'],\n",
    "    [4.9,2.5,4.5,1.7,'Iris-virginica'],\n",
    "    [7.3,2.9,6.3,1.8,'Iris-virginica'],\n",
    "    [6.7,2.5,5.8,1.8,'Iris-virginica'],\n",
    "    [7.2,3.6,6.1,2.5,'Iris-virginica'],\n",
    "    [6.5,3.2,5.1,2.0,'Iris-virginica'],\n",
    "    [6.4,2.7,5.3,1.9,'Iris-virginica'],\n",
    "    [6.8,3.0,5.5,2.1,'Iris-virginica'],\n",
    "    [5.7,2.5,5.0,2.0,'Iris-virginica'],\n",
    "    [5.8,2.8,5.1,2.4,'Iris-virginica'],\n",
    "    [6.4,3.2,5.3,2.3,'Iris-virginica'],\n",
    "    [6.5,3.0,5.5,1.8,'Iris-virginica'],\n",
    "    [7.7,3.8,6.7,2.2,'Iris-virginica'],\n",
    "    [7.7,2.6,6.9,2.3,'Iris-virginica'],\n",
    "    [6.0,2.2,5.0,1.5,'Iris-virginica'],\n",
    "    [6.9,3.2,5.7,2.3,'Iris-virginica'],\n",
    "    [5.6,2.8,4.9,2.0,'Iris-virginica'],\n",
    "    [7.7,2.8,6.7,2.0,'Iris-virginica'],\n",
    "    [6.3,2.7,4.9,1.8,'Iris-virginica'],\n",
    "    [6.7,3.3,5.7,2.1,'Iris-virginica'],\n",
    "    [7.2,3.2,6.0,1.8,'Iris-virginica'],\n",
    "    [6.2,2.8,4.8,1.8,'Iris-virginica'],\n",
    "    [6.1,3.0,4.9,1.8,'Iris-virginica'],\n",
    "    [6.4,2.8,5.6,2.1,'Iris-virginica'],\n",
    "    [7.2,3.0,5.8,1.6,'Iris-virginica'],\n",
    "    [7.4,2.8,6.1,1.9,'Iris-virginica'],\n",
    "    [7.9,3.8,6.4,2.0,'Iris-virginica'],\n",
    "    [6.4,2.8,5.6,2.2,'Iris-virginica'],\n",
    "    [6.3,2.8,5.1,1.5,'Iris-virginica'],\n",
    "    [6.1,2.6,5.6,1.4,'Iris-virginica'],\n",
    "    [7.7,3.0,6.1,2.3,'Iris-virginica'],\n",
    "    [6.3,3.4,5.6,2.4,'Iris-virginica'],\n",
    "    [6.4,3.1,5.5,1.8,'Iris-virginica'],\n",
    "    [6.0,3.0,4.8,1.8,'Iris-virginica'],\n",
    "    [6.9,3.1,5.4,2.1,'Iris-virginica'],\n",
    "    [6.7,3.1,5.6,2.4,'Iris-virginica'],\n",
    "    [6.9,3.1,5.1,2.3,'Iris-virginica'],\n",
    "    [5.8,2.7,5.1,1.9,'Iris-virginica'],\n",
    "    [6.8,3.2,5.9,2.3,'Iris-virginica'],\n",
    "    [6.7,3.3,5.7,2.5,'Iris-virginica'],\n",
    "    [6.7,3.0,5.2,2.3,'Iris-virginica'],\n",
    "    [6.3,2.5,5.0,1.9,'Iris-virginica'],\n",
    "    [6.5,3.0,5.2,2.0,'Iris-virginica'],\n",
    "    [6.2,3.4,5.4,2.3,'Iris-virginica'],\n",
    "    [5.9,3.0,5.1,1.8,'Iris-virginica']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8091af",
   "metadata": {
    "papermill": {
     "duration": 0.011385,
     "end_time": "2023-04-21T21:40:05.666708",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.655323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## What to Do\n",
    "\n",
    "Demonstrate your understanding and ability to have synthesized course concepts by providing a walkthrough, with both code and prose, that demonstrates a simple ML workflow. Your goal is to pick an ideal **_k_** for the classifier and demonstrate a methodical justification for your selection. In the end, your work should reflect the principles seen thus far in the course.\n",
    "\n",
    "Please be sure to demonstrate:\n",
    "\n",
    "1. Splitting a data set into appropriate training and test sets\n",
    "2. \"Training\" a k-NN classifier\n",
    "3. Repeatedly testing a k-NN classifier with different values of `k`, and reporting the generalization errors for each `k`\n",
    "4. Analyzing the generalization errors for different values of `k`\n",
    "5. Identifying the ideal `k` value for this classifier, and justifying your selection by demonstrating a sound process (not just assertion)\n",
    "\n",
    "### Tips\n",
    "\n",
    "1. Be sure that you have spent time with the Exploration materials in this course.\n",
    "2. Ask questions on the course forum if you get stuck (describe what you are trying to do, and errors that you encounter)\n",
    "3. **Keep it simple.** This is more straightforward than it may initially seem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a20428",
   "metadata": {
    "papermill": {
     "duration": 0.011507,
     "end_time": "2023-04-21T21:40:05.689792",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.678285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Producing a Training Set and Test Set\n",
    "\n",
    "The code first imports the random library, then creates the ` split_index`  variable using the int function to convert the result of multiplying 0.6 by the length of ` iris_data_set`  into an integer.\n",
    "\n",
    "After creating two new lists, and splitting them 60/40 by using slicing notation, where`iris_data_set[:split_index]` selects all of the elements of `iris_data_set`  from the beginning to`split_index`, while `iris_data_set[split_index:]`  selects all elements from the `split_index` to the end of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943867db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:05.715008Z",
     "iopub.status.busy": "2023-04-21T21:40:05.714209Z",
     "iopub.status.idle": "2023-04-21T21:40:05.721830Z",
     "shell.execute_reply": "2023-04-21T21:40:05.720577Z"
    },
    "papermill": {
     "duration": 0.023964,
     "end_time": "2023-04-21T21:40:05.725118",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.701154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Split into training and test sets\n",
    "split_index = int(0.6 * len(iris_data_set))\n",
    "iris_training_set = iris_data_set[:split_index]\n",
    "iris_test_set = iris_data_set[split_index:]\n",
    "\n",
    "print(len(iris_training_set))\n",
    "print(len(iris_test_set))      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218a584",
   "metadata": {
    "papermill": {
     "duration": 0.010964,
     "end_time": "2023-04-21T21:40:05.747523",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.736559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, we can see that the number of records split and randomize. There are 90 records for iris_training_set, and 60 records for iris_test_set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d6997",
   "metadata": {
    "papermill": {
     "duration": 0.010923,
     "end_time": "2023-04-21T21:40:05.769900",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.758977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the Classifier\n",
    "\n",
    "I am setting `k=3`, which means that we're using the 3 nearest neighbors to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade850f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:05.795838Z",
     "iopub.status.busy": "2023-04-21T21:40:05.795380Z",
     "iopub.status.idle": "2023-04-21T21:40:05.801138Z",
     "shell.execute_reply": "2023-04-21T21:40:05.799245Z"
    },
    "papermill": {
     "duration": 0.021122,
     "end_time": "2023-04-21T21:40:05.803485",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.782363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the KnnClassifier on the iris_training_set\n",
    "knn = KnnClassifier(k=3)  # set k=3 for this example\n",
    "knn.train(iris_training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e414a",
   "metadata": {
    "papermill": {
     "duration": 0.011322,
     "end_time": "2023-04-21T21:40:05.826762",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.815440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Repeatedly testing a k-NN classifier with different values of k, and reporting the generalization errors for each k\n",
    "\n",
    "When repeatedly testing the k-NN classifier with different values of k, I created a loop that iterates through a range of k values and have it compute the generalization error for each value of k.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f3cc20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:05.852249Z",
     "iopub.status.busy": "2023-04-21T21:40:05.851837Z",
     "iopub.status.idle": "2023-04-21T21:40:06.095534Z",
     "shell.execute_reply": "2023-04-21T21:40:06.093951Z"
    },
    "papermill": {
     "duration": 0.259554,
     "end_time": "2023-04-21T21:40:06.098178",
     "exception": false,
     "start_time": "2023-04-21T21:40:05.838624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1, error rate = 0.83\n",
      "k = 2, error rate = 0.83\n",
      "k = 3, error rate = 0.83\n",
      "k = 4, error rate = 0.83\n",
      "k = 5, error rate = 0.83\n",
      "k = 6, error rate = 0.83\n",
      "k = 7, error rate = 0.83\n",
      "k = 8, error rate = 0.83\n",
      "k = 9, error rate = 0.83\n",
      "k = 10, error rate = 0.83\n",
      "k = 11, error rate = 0.83\n",
      "k = 12, error rate = 0.83\n",
      "k = 13, error rate = 0.83\n",
      "k = 14, error rate = 0.83\n",
      "k = 15, error rate = 0.83\n",
      "k = 16, error rate = 0.83\n",
      "k = 17, error rate = 0.83\n",
      "k = 18, error rate = 0.83\n",
      "k = 19, error rate = 0.83\n",
      "k = 20, error rate = 0.83\n"
     ]
    }
   ],
   "source": [
    "# Test the classifier with different values of k\n",
    "for k in range(1, 21):\n",
    "    classifier = KnnClassifier(k)\n",
    "    classifier.train(iris_training_set)\n",
    "    error_rate = 1 - classifier.test(iris_test_set)\n",
    "    print(f\"k = {k}, error rate = {error_rate:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a57242",
   "metadata": {
    "papermill": {
     "duration": 0.011188,
     "end_time": "2023-04-21T21:40:06.121534",
     "exception": false,
     "start_time": "2023-04-21T21:40:06.110346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The point of the loop I've created is to iterate through values of k from 1 to 20, and for each value of k. After creating a new instance of the KnnClasifier based on the value of k. I have it train on the training set and spit out the error rate on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83557505",
   "metadata": {
    "papermill": {
     "duration": 0.011059,
     "end_time": "2023-04-21T21:40:06.143946",
     "exception": false,
     "start_time": "2023-04-21T21:40:06.132887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Analyzing the generalization errors for different values of k\n",
    "\n",
    "Here, I use the matplotlib library to help create a visual plot. I created a plot of graph to show where the x-axis represents the value of k, and the y-axis represents the generalization error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7afd5930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:06.168965Z",
     "iopub.status.busy": "2023-04-21T21:40:06.168548Z",
     "iopub.status.idle": "2023-04-21T21:40:06.538536Z",
     "shell.execute_reply": "2023-04-21T21:40:06.537213Z"
    },
    "papermill": {
     "duration": 0.38565,
     "end_time": "2023-04-21T21:40:06.541281",
     "exception": false,
     "start_time": "2023-04-21T21:40:06.155631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 20]\n",
    "errors = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KnnClassifier(k=k)\n",
    "    knn.train(iris_training_set)\n",
    "    error = 1 - knn.test(iris_test_set)\n",
    "    errors.append(error)\n",
    "    \n",
    "plt.plot(k_values, errors)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Generalization error')\n",
    "plt.title('Generalization error for different values of k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbeed79",
   "metadata": {
    "papermill": {
     "duration": 0.012115,
     "end_time": "2023-04-21T21:40:06.565678",
     "exception": false,
     "start_time": "2023-04-21T21:40:06.553563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Based on this plot, I am testing the k-NN classifier with the values of k from 1 to 20. The plotted values of k is on the x-axis and the generalization errors is on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67fadb0",
   "metadata": {
    "papermill": {
     "duration": 0.011487,
     "end_time": "2023-04-21T21:40:06.588953",
     "exception": false,
     "start_time": "2023-04-21T21:40:06.577466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Identifying the ideal k value for this classifier, and justifying your selection by demonstrating a sound process \n",
    "\n",
    "In this chunk of code, I made it iterate over the values of k from 1 to 20 and train the k-NN classifier on the training set. It is able to compute and spit out the generalization error on the test set. The errors for each value of k is printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101089b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:06.615153Z",
     "iopub.status.busy": "2023-04-21T21:40:06.613976Z",
     "iopub.status.idle": "2023-04-21T21:40:06.842062Z",
     "shell.execute_reply": "2023-04-21T21:40:06.840731Z"
    },
    "papermill": {
     "duration": 0.243966,
     "end_time": "2023-04-21T21:40:06.844623",
     "exception": false,
     "start_time": "2023-04-21T21:40:06.600657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1, error = 0.8333333333333334\n",
      "k = 2, error = 0.8333333333333334\n",
      "k = 3, error = 0.8333333333333334\n",
      "k = 4, error = 0.8333333333333334\n",
      "k = 5, error = 0.8333333333333334\n",
      "k = 6, error = 0.8333333333333334\n",
      "k = 7, error = 0.8333333333333334\n",
      "k = 8, error = 0.8333333333333334\n",
      "k = 9, error = 0.8333333333333334\n",
      "k = 10, error = 0.8333333333333334\n",
      "k = 11, error = 0.8333333333333334\n",
      "k = 12, error = 0.8333333333333334\n",
      "k = 13, error = 0.8333333333333334\n",
      "k = 14, error = 0.8333333333333334\n",
      "k = 15, error = 0.8333333333333334\n",
      "k = 16, error = 0.8333333333333334\n",
      "k = 17, error = 0.8333333333333334\n",
      "k = 18, error = 0.8333333333333334\n",
      "k = 19, error = 0.8333333333333334\n",
      "Best k = 1, Best error = 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "best_k = None\n",
    "best_error = float('inf')\n",
    "for k in range(1, 20):\n",
    "    knn = KnnClassifier(k)\n",
    "    knn.train(iris_training_set)\n",
    "    error = 1 - knn.test(iris_test_set)\n",
    "    print(f\"k = {k}, error = {error}\")\n",
    "    if error < best_error:\n",
    "        best_k = k\n",
    "        best_error = error\n",
    "\n",
    "print(f\"Best k = {best_k}, Best error = {best_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e834903",
   "metadata": {
    "papermill": {
     "duration": 0.011569,
     "end_time": "2023-04-21T21:40:06.868234",
     "exception": false,
     "start_time": "2023-04-21T21:40:06.856665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After computing the best value of k, the best k is when k=1, and the best error is 0.8333333333333334. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc669ba3",
   "metadata": {
    "papermill": {
     "duration": 0.011485,
     "end_time": "2023-04-21T21:40:06.891562",
     "exception": false,
     "start_time": "2023-04-21T21:40:06.880077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Write a review of what you did, some key decisions you made along the way and why you made those decisions, the end result, and what you might do next or experiment with next to achieve a higher performing classifier.\n",
    "\n",
    "###  Knowledge Check Part 1\n",
    "\n",
    "*I created a code that first splits the dataset into a training set and a test set using slicing notation. It then trains a k-NN classifier on the training set, and tests it with different values of k using a loop that iterates over the values of k. For each value of k, it trains the k-NN classifier on the training set and tests it on the test set, and then prints out the generalization error. The code then creates a plot of the generalization errors for different values of k using the matplotlib library. It then identifies the best k value for the classifier based on the lowest generalization error.* \n",
    "\n",
    "*One key decision I made was the choice of the spliting ratio between the training set and test set, which was set to 60/40. There are many popular options from what I've read such as; 80/20, 70/30, 95/5. Another decision was the choice of k values to test, which was set to a range of values from 1 to 20. I personally felt like 10 was too short, and 30 was a bit much.*\n",
    "\n",
    "*The end result of the code is a plot that shows the generalization errors for different values of k, and the best k value for the classifier based on the lowest generalization error.* \n",
    "\n",
    "*On my next experiment in acheiving a higher performing classifier, I could play around with a much bigger set of values of k. I could use different split ratios between the training set and test set, or with different methods for splitting the dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b87817",
   "metadata": {
    "papermill": {
     "duration": 0.011604,
     "end_time": "2023-04-21T21:40:06.914923",
     "exception": false,
     "start_time": "2023-04-21T21:40:06.903319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 2: Classifying Handwritten Digits\n",
    "\n",
    "In this, the second, part of this notebook, we will build a classifier that can assign a label, 0 - 9, to images of hand-written digits. We'll use a preprocessed subset of the well-known [MNIST database of handwritten digits](https://en.wikipedia.org/wiki/MNIST_database). Take a moment now to familiarize yourself with the subject matter of this data set, and take a look at the properties of [the UCI ML hand-written digits dataset](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits).\n",
    "\n",
    "## What to Do\n",
    "\n",
    "We'll guide you one step at a time in this walkthrough of a k-NN workflow. Try out the code, answer the Knowledge Check questions along the way, and engage in a few challenges to exercise your understanding and have some fun.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "We would like to \"transform\" sequences of handwritten digits into real numeric values that a computer can understand. For example, we would like a machine to be able to \"read\" a handwritten **8675309** and interpret each digit, resulting in the numeric string `8675309`. As such, we would like to construct a classifier that, as accurately as possible, can identify a visual representation of integers (pictures of handwritten numbers), and classify each image with one of ten labels: 0, 1, 2, 3, 4, 5, 6, 7, 8 or 9.\n",
    "\n",
    "## Obtaining the data\n",
    "\n",
    "For this experiment, we will get up and running quickly with [a subset of the MNIST data, bundled in the scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) library. First, let's import a typical toolkit of libraries, including pandas, matplotlib, and [scikit-learn](https://scikit-learn.org/stable/index.html).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "```\n",
    "\n",
    "Here we are importing two essential libraries, and giving them aliases `pd`, `plt`, and importing the `load_digits` function, which will give use our data set.\n",
    "\n",
    "Let's load the data into memory as well, assigning it to a variable.\n",
    "\n",
    "```python\n",
    "digits = load_digits(as_frame=True)\n",
    "```\n",
    "\n",
    "Note that `load_digits` returns a [Bunch](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch) object - not a pandas DataFrame. Review the [load_digits documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) to see what the attributes of our particular Bunch are. We pass `load_digits` the named argument `as_frame=True` up front now, so that we can access the data as a DataFrame later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef1d7171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:06.941256Z",
     "iopub.status.busy": "2023-04-21T21:40:06.940105Z",
     "iopub.status.idle": "2023-04-21T21:40:08.116497Z",
     "shell.execute_reply": "2023-04-21T21:40:08.115316Z"
    },
    "papermill": {
     "duration": 1.192547,
     "end_time": "2023-04-21T21:40:08.119214",
     "exception": false,
     "start_time": "2023-04-21T21:40:06.926667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import a typical toolkit of libraries, including pandas, matplotlib, and scikit-learn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "#load the data into memory\n",
    "digits = load_digits(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e118b",
   "metadata": {
    "papermill": {
     "duration": 0.011729,
     "end_time": "2023-04-21T21:40:08.143535",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.131806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Exploring the Data\n",
    "\n",
    "Let's investigate the description, shape, feature names, and target label names of the `data` set stored in the Bunch. We know about these attributes from the documentation of [`load_digits`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits). Try inspecting each of these properties one at a time.\n",
    "\n",
    "```python\n",
    "print(digits.DESCR)\n",
    "digits.data.shape\n",
    "digits.feature_names\n",
    "digits.target_names\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f66242a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:08.169291Z",
     "iopub.status.busy": "2023-04-21T21:40:08.168877Z",
     "iopub.status.idle": "2023-04-21T21:40:08.178250Z",
     "shell.execute_reply": "2023-04-21T21:40:08.176468Z"
    },
    "papermill": {
     "duration": 0.025356,
     "end_time": "2023-04-21T21:40:08.180813",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.155457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(digits.DESCR)\n",
    "digits.data.shape\n",
    "digits.feature_names\n",
    "digits.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435bbd3",
   "metadata": {
    "papermill": {
     "duration": 0.011849,
     "end_time": "2023-04-21T21:40:08.204788",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.192939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  Knowledge Check 1\n",
    "\n",
    "1. How many individual handwritten characters are represented in the data set?\n",
    "\n",
    "*There are 1797 individual handwritten characters represented in the data set*\n",
    "\n",
    "2. How many dimensions are there, not counting the class label?\n",
    "\n",
    "*There are 64 dimensions not counting the class label*\n",
    "\n",
    "3. What do the dimensions of each record represent? (What does one row of data have to do with a handwritten digit?)\n",
    "\n",
    "*The dimensions of each record represent the intensity of each 8x8 image of integer pixels. Each row of data contains information about one image of a digit, therefore each dimension of that one pixel is the brightness, where it applies to the optical character recognition application.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51d57e",
   "metadata": {
    "papermill": {
     "duration": 0.011912,
     "end_time": "2023-04-21T21:40:08.229274",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.217362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "#### Exploring the DataFrame\n",
    "\n",
    "Now, let's access the data as a pandas DataFrame, for convenience and some quick summary stats.\n",
    "\n",
    "```python\n",
    "frame = digits.frame\n",
    "frame\n",
    "```\n",
    "\n",
    "Here we are obtaining the DataFrame, and inspecting it within the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7818f32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:08.256385Z",
     "iopub.status.busy": "2023-04-21T21:40:08.255222Z",
     "iopub.status.idle": "2023-04-21T21:40:08.308734Z",
     "shell.execute_reply": "2023-04-21T21:40:08.307420Z"
    },
    "papermill": {
     "duration": 0.069948,
     "end_time": "2023-04-21T21:40:08.311479",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.241531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows  65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
       "\n",
       "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
       "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
       "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
       "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
       "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
       "\n",
       "      pixel_7_7  target  \n",
       "0           0.0       0  \n",
       "1           0.0       1  \n",
       "2           0.0       2  \n",
       "3           0.0       3  \n",
       "4           0.0       4  \n",
       "...         ...     ...  \n",
       "1792        0.0       9  \n",
       "1793        0.0       0  \n",
       "1794        0.0       8  \n",
       "1795        0.0       9  \n",
       "1796        0.0       8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = digits.frame\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184e66f",
   "metadata": {
    "papermill": {
     "duration": 0.012332,
     "end_time": "2023-04-21T21:40:08.336698",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.324366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's investigate some summary statistics with `describe`.\n",
    "\n",
    "```python\n",
    "frame.describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ded5c686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:08.364590Z",
     "iopub.status.busy": "2023-04-21T21:40:08.363700Z",
     "iopub.status.idle": "2023-04-21T21:40:08.530972Z",
     "shell.execute_reply": "2023-04-21T21:40:08.529802Z"
    },
    "papermill": {
     "duration": 0.185176,
     "end_time": "2023-04-21T21:40:08.534581",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.349405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1797.0</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303840</td>\n",
       "      <td>5.204786</td>\n",
       "      <td>11.835838</td>\n",
       "      <td>11.848080</td>\n",
       "      <td>5.781859</td>\n",
       "      <td>1.362270</td>\n",
       "      <td>0.129661</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>1.993879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206455</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.279354</td>\n",
       "      <td>5.557596</td>\n",
       "      <td>12.089037</td>\n",
       "      <td>11.809126</td>\n",
       "      <td>6.764051</td>\n",
       "      <td>2.067891</td>\n",
       "      <td>0.364496</td>\n",
       "      <td>4.490818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907192</td>\n",
       "      <td>4.754826</td>\n",
       "      <td>4.248842</td>\n",
       "      <td>4.287388</td>\n",
       "      <td>5.666418</td>\n",
       "      <td>3.325775</td>\n",
       "      <td>1.037383</td>\n",
       "      <td>0.094222</td>\n",
       "      <td>3.196160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984401</td>\n",
       "      <td>0.023590</td>\n",
       "      <td>0.934302</td>\n",
       "      <td>5.103019</td>\n",
       "      <td>4.374694</td>\n",
       "      <td>4.933947</td>\n",
       "      <td>5.900623</td>\n",
       "      <td>4.090548</td>\n",
       "      <td>1.860122</td>\n",
       "      <td>2.865304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel_0_0    pixel_0_1    pixel_0_2    pixel_0_3    pixel_0_4  \\\n",
       "count     1797.0  1797.000000  1797.000000  1797.000000  1797.000000   \n",
       "mean         0.0     0.303840     5.204786    11.835838    11.848080   \n",
       "std          0.0     0.907192     4.754826     4.248842     4.287388   \n",
       "min          0.0     0.000000     0.000000     0.000000     0.000000   \n",
       "25%          0.0     0.000000     1.000000    10.000000    10.000000   \n",
       "50%          0.0     0.000000     4.000000    13.000000    13.000000   \n",
       "75%          0.0     0.000000     9.000000    15.000000    15.000000   \n",
       "max          0.0     8.000000    16.000000    16.000000    16.000000   \n",
       "\n",
       "         pixel_0_5    pixel_0_6    pixel_0_7    pixel_1_0    pixel_1_1  ...  \\\n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  ...   \n",
       "mean      5.781859     1.362270     0.129661     0.005565     1.993879  ...   \n",
       "std       5.666418     3.325775     1.037383     0.094222     3.196160  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%      11.000000     0.000000     0.000000     0.000000     3.000000  ...   \n",
       "max      16.000000    16.000000    15.000000     2.000000    16.000000  ...   \n",
       "\n",
       "         pixel_6_7    pixel_7_0    pixel_7_1    pixel_7_2    pixel_7_3  \\\n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000   \n",
       "mean      0.206455     0.000556     0.279354     5.557596    12.089037   \n",
       "std       0.984401     0.023590     0.934302     5.103019     4.374694   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     1.000000    11.000000   \n",
       "50%       0.000000     0.000000     0.000000     4.000000    13.000000   \n",
       "75%       0.000000     0.000000     0.000000    10.000000    16.000000   \n",
       "max      13.000000     1.000000     9.000000    16.000000    16.000000   \n",
       "\n",
       "         pixel_7_4    pixel_7_5    pixel_7_6    pixel_7_7       target  \n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  \n",
       "mean     11.809126     6.764051     2.067891     0.364496     4.490818  \n",
       "std       4.933947     5.900623     4.090548     1.860122     2.865304  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%      10.000000     0.000000     0.000000     0.000000     2.000000  \n",
       "50%      14.000000     6.000000     0.000000     0.000000     4.000000  \n",
       "75%      16.000000    12.000000     2.000000     0.000000     7.000000  \n",
       "max      16.000000    16.000000    16.000000    16.000000     9.000000  \n",
       "\n",
       "[8 rows x 65 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59561c2d",
   "metadata": {
    "papermill": {
     "duration": 0.013044,
     "end_time": "2023-04-21T21:40:08.561405",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.548361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We know from `DESCR` that the pixel values range from 0 to 16, and our quick survey of `describe` seems to confirm this, so we'll move forward with our assumptions about the data set. (In addition, `DESCR` promises us that there are no missing values - the preprocessing work has been done.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f0964",
   "metadata": {
    "papermill": {
     "duration": 0.01289,
     "end_time": "2023-04-21T21:40:08.587638",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.574748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  Knowledge Check 2\n",
    "\n",
    "Based on the summary statistics, what is interesting about attribute *pixel_0_0*, and what do those interesting qualities lead you to conclude? Please describe it in very approachable terms, regarding the handwritten images, that anyone can understand.\n",
    "\n",
    "*Based on the summary statistics, what is interesting about attribute *pixel_0_0* is that it has a minimum value of 0 and a maximum value of 0. It also a value of 0 in the column itself across all statistics. What it means is that every image in the dataset will have a a blank or white pixel in that particular spot. If that is the case, it might not be useful to use in analysis.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf51fe1",
   "metadata": {
    "papermill": {
     "duration": 0.012789,
     "end_time": "2023-04-21T21:40:08.613850",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.601061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualize the Data\n",
    "\n",
    "Let's take a visual look at one of the images. The `digits` Bunch has a property, `images`, that is an array of all of the raw image data. Let's access one image and visualize it on the screen.\n",
    "\n",
    "```python\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "856a28bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:08.642647Z",
     "iopub.status.busy": "2023-04-21T21:40:08.642216Z",
     "iopub.status.idle": "2023-04-21T21:40:08.926307Z",
     "shell.execute_reply": "2023-04-21T21:40:08.924819Z"
    },
    "papermill": {
     "duration": 0.302746,
     "end_time": "2023-04-21T21:40:08.929818",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.627072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7767f5",
   "metadata": {
    "papermill": {
     "duration": 0.015997,
     "end_time": "2023-04-21T21:40:08.968489",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.952492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  Knowledge Check 3\n",
    "\n",
    "1. The figure is drawn at a scale of 640x480 pixels, but how many pixels wide and tall are the actual character images?\n",
    "\n",
    "*Based on the figure drawn at scale above, there are 8x8 pixels wide and tall*\n",
    "\n",
    "2. What does this have to do with the dimensions of the data set?\n",
    "\n",
    "*What this have to do with the dimensions is that each image in the dataset has 64 features that are individual pixel values, and it is important when we know how to analyze and process the data when looking at these individual pixel values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4f647",
   "metadata": {
    "papermill": {
     "duration": 0.01336,
     "end_time": "2023-04-21T21:40:08.995627",
     "exception": false,
     "start_time": "2023-04-21T21:40:08.982267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare the Training and Validation Sets\n",
    "\n",
    "With preprocessing gratefully handled for us, we now turn to creating our training set and validation sets. While we could manually implement our own sampling technique, this time we will lean on the `sklearn.model_selection.train_test_split` method. Be sure to check out the documentation for [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=0)\n",
    "```\n",
    "\n",
    "Notice how we pass `train_test_split` two arrays: one array, `digits.data`, containing all of the attributes except the class label dimension, and a second array, `digits.target`, containing the class labels for each record in the data set. We also specify that we'd like to use 80% of the records for training, and 20% of the records for testing. (Here we are also assigning `0` to `random_state`, and this is only for the sake of this exercise, to control the random seed so that running our notebook repeatedly gives us the same, albeit randomized, sampling.)\n",
    "\n",
    "The function `train_test_split` returns four arrays, conveniently splitting our complete data set into randomized training and validation sets:\n",
    "\n",
    "- `X_train`: our training records, without the class labels\n",
    "- `y_train`: the class labels for our training records\n",
    "- `X_test`: our validation records, without the class labels\n",
    "- `y_test`: the class labels for our validation records\n",
    "\n",
    "This is a very common naming convention we see in practice, so we'll abide by it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c8bfe0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:09.025368Z",
     "iopub.status.busy": "2023-04-21T21:40:09.024923Z",
     "iopub.status.idle": "2023-04-21T21:40:09.087102Z",
     "shell.execute_reply": "2023-04-21T21:40:09.086036Z"
    },
    "papermill": {
     "duration": 0.080643,
     "end_time": "2023-04-21T21:40:09.089887",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.009244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758570a",
   "metadata": {
    "papermill": {
     "duration": 0.0137,
     "end_time": "2023-04-21T21:40:09.117230",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.103530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Instantiate and \"Train\" our Classifier\n",
    "\n",
    "We'll next instantiate a k-NN classifier provided by scikit-learn: the [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). Please be sure to read the documentation, noticing both the parameters we can pass the KNeighborsClassifier initializer, such as the distance metric to use, and in particular, `n_neighbors` which is our **_k_**.\n",
    "\n",
    "We'll rely on some defaults, but start with a fairly unsurprising **_k_**, the square root of the number of records in the training set.\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = int(sqrt(len(X_train))))\n",
    "```\n",
    "\n",
    "Import the KNeighborsClassifier and instantiate it the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2c39b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:09.146993Z",
     "iopub.status.busy": "2023-04-21T21:40:09.146550Z",
     "iopub.status.idle": "2023-04-21T21:40:09.328944Z",
     "shell.execute_reply": "2023-04-21T21:40:09.327674Z"
    },
    "papermill": {
     "duration": 0.200555,
     "end_time": "2023-04-21T21:40:09.331709",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.131154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=int(sqrt(len(X_train))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5a8e0",
   "metadata": {
    "papermill": {
     "duration": 0.013218,
     "end_time": "2023-04-21T21:40:09.358996",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.345778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we have to \"train our model,\" but, as we know, k-NN classifiers are instance-based learners with no initial training computation. All we need to do is provide the classifier with the training data.\n",
    "\n",
    "```python\n",
    "classifier.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Here we invoke the commonplace `fit` method found in tha API of many pre-built classification models. Here, we simply pass it our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb6b4348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:09.388803Z",
     "iopub.status.busy": "2023-04-21T21:40:09.387897Z",
     "iopub.status.idle": "2023-04-21T21:40:09.403518Z",
     "shell.execute_reply": "2023-04-21T21:40:09.402437Z"
    },
    "papermill": {
     "duration": 0.032999,
     "end_time": "2023-04-21T21:40:09.405748",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.372749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=37)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab34a3",
   "metadata": {
    "papermill": {
     "duration": 0.013564,
     "end_time": "2023-04-21T21:40:09.433603",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.420039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  Knowledge Check 4\n",
    "\n",
    "Using the documentation, investigate the other \"nearest neighbor\" classifiers in the scikit-learn library, in the `sklearn.neighbors` namespace. Identify (name) two other classifiers, and briefly describe how they are different from KNeighborsClassifier. Don't just regurgitate the documentation - do a little online sleuthing to see how they are useful, and share that information here.\n",
    "\n",
    "*Based on what I found, two other nearest neighbor classifiers in the scikit-learn library are RadiusNeighborsClassifer and KNeighborsRegressor. The RadiusNeighborsClassifer is based on radius of points around an observation, and predicts the class of a test point based on the points within a fixed radius area. When finding the neighbors within a given radius of a point or points, it return the indices and distances of each point from the dataset lying in a ball with size radius around the points of the query array. Points lying on the boundary are included in the results.*\n",
    "*I believe it is useful when the data is not well-defined or if there is a large amount of noise in the data.*\n",
    "\n",
    "*KNeighborsRegressor seems to be a regression algorithm and it is use to predict a continious output variable. The target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set. It also works by finding the k-nearest neighbors and taking the average as a predicted value. I believe it is useful when needing to predict a continious variable based on a set of input variables.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a87c50a",
   "metadata": {
    "papermill": {
     "duration": 0.013137,
     "end_time": "2023-04-21T21:40:09.460249",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.447112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Validate (Test) Our Classifier\n",
    "\n",
    "The next step in our ML process is to see how well our classifier performs, given our training set and, in this case, our initial **_k_**. We'll ask the classifier to predict the class label for every record in our validation set, `X_test`. Then, we'll compare those predictions with the actual class labels, in `y_test`, and compute an accuracy score. Rather than do this manually, we'll rely on the scikit-learn [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function. Be sure to read the documentation for `accuracy_score`.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predictions = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predictions)\n",
    "```\n",
    "\n",
    "Here we invoke the KNeighborsClassifier `predict` method, which returns an array of predicted class labels for each record in `X_test`, that we assign to `y_predictions`. We then pass `accuracy_score` the known correct class labels for the validation set, `y_test`, and the predicted labels, `y_predictions`, and let it make the comparisons, tally up the correct matches, and compute and return an accuracy score between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "def63c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:09.490443Z",
     "iopub.status.busy": "2023-04-21T21:40:09.489976Z",
     "iopub.status.idle": "2023-04-21T21:40:09.541107Z",
     "shell.execute_reply": "2023-04-21T21:40:09.539622Z"
    },
    "papermill": {
     "duration": 0.070508,
     "end_time": "2023-04-21T21:40:09.544814",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.474306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predictions = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b2e5b5",
   "metadata": {
    "papermill": {
     "duration": 0.022042,
     "end_time": "2023-04-21T21:40:09.589628",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.567586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's inspect that accuracy score by simply printing it.\n",
    "\n",
    "```python\n",
    "print(accuracy)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf7317f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:09.632212Z",
     "iopub.status.busy": "2023-04-21T21:40:09.631430Z",
     "iopub.status.idle": "2023-04-21T21:40:09.637885Z",
     "shell.execute_reply": "2023-04-21T21:40:09.636641Z"
    },
    "papermill": {
     "duration": 0.028449,
     "end_time": "2023-04-21T21:40:09.640509",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.612060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a98b708",
   "metadata": {
    "papermill": {
     "duration": 0.013393,
     "end_time": "2023-04-21T21:40:09.667589",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.654196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hm - not bad!\n",
    "\n",
    "There's one more way we can analyze the performance of our classifier: by inspecting a matrix of expected vs predicted class labels, known as a *confusion matrix*. For each cell in the matrix, we'll see the number of predictions, whether right or wrong, made for each of the known class labels.\n",
    "\n",
    "We'll reach for the scikit-learn [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function to generate a confusion matrix for us.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_predictions)\n",
    "```\n",
    "\n",
    "We import the `confusion_matrix` function, and then invoke it, passing it the expected class labels in the validation set, `y_test`, and the predicted labels, `y_predictions`. It returns, in essence, a matrix, which we assign to `confusion_matrix`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba85098e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:09.697726Z",
     "iopub.status.busy": "2023-04-21T21:40:09.696838Z",
     "iopub.status.idle": "2023-04-21T21:40:09.704818Z",
     "shell.execute_reply": "2023-04-21T21:40:09.703852Z"
    },
    "papermill": {
     "duration": 0.025651,
     "end_time": "2023-04-21T21:40:09.707172",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.681521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6e9c7",
   "metadata": {
    "papermill": {
     "duration": 0.013839,
     "end_time": "2023-04-21T21:40:09.734995",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.721156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's inspect the confusion matrix by simply printing it.\n",
    "\n",
    "```python\n",
    "print(confusion_matrix)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddc31bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:09.764686Z",
     "iopub.status.busy": "2023-04-21T21:40:09.763827Z",
     "iopub.status.idle": "2023-04-21T21:40:09.770854Z",
     "shell.execute_reply": "2023-04-21T21:40:09.769567Z"
    },
    "papermill": {
     "duration": 0.024547,
     "end_time": "2023-04-21T21:40:09.773169",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.748622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 35  0  0  0  0  0  0  0  0]\n",
      " [ 1  0 32  1  0  0  0  1  1  0]\n",
      " [ 0  0  0 29  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 29  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 39  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 39  0  0]\n",
      " [ 0  3  0  1  0  0  1  1 33  0]\n",
      " [ 0  0  0  0  0  1  0  1  0 39]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47c6b9",
   "metadata": {
    "papermill": {
     "duration": 0.013506,
     "end_time": "2023-04-21T21:40:09.800577",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.787071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The horizontal axis of a confusion matrix represents the predicted labels, and the vertical axis represents the correct class labels. Each entry in the matrix represents the number of images predicted to have that class label.\n",
    "\n",
    "Notice how well this classifer performed, with our default **_k_**, euclidean distance, and a (luckily!) high-quality data set. We can see the 27 of the **0** handwritten images are correctly classified, and none are misclassified. If we look at the last row in the confusion matrix, we see that 39 of the **9** images are correctly classified, but one was classified as a **5**, and another classified as a **7**.\n",
    "\n",
    "### But, can you do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe52bc1e",
   "metadata": {
    "papermill": {
     "duration": 0.013564,
     "end_time": "2023-04-21T21:40:09.828000",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.814436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  Knowledge Check 5\n",
    "\n",
    "Inspect the confusion matrix. Which handwritten letter seemed to be the \"hardest\" for our classifier to predict correctly? What evidence in the confusion matrix leads you to assert this?\n",
    "\n",
    "*After analyzing the confusion matrix, it seems that the handwritten letter that seems to be the hardest for the classifer to predict correctly is digit 8. There seems to be more misclassifications than in any other row. multiple image of 8 was classified as 1, another one image was 3.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3ec18",
   "metadata": {
    "papermill": {
     "duration": 0.013254,
     "end_time": "2023-04-21T21:40:09.855135",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.841881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tune the Classifier: Find the Best **_k_**\n",
    "\n",
    "Now it's your turn. Given what we have seen in the course thus far, and the `sklearn` API seen in this notebook, create an iterative experiment that inspects the accuracy of different classifiers using different **_k_** values. Your goal is to configure a classifier that exhibits the highest possible accuracy. Start your experiment with the traditional initial **_k_**, the square root of the number of records in the training set.\n",
    "\n",
    "Your experiment should demonstrate:\n",
    "\n",
    "- Creating KNeighborsClassifiers with different **_k_** values\n",
    "- \"Training\" and validating the classifiers\n",
    "- Capturing and presenting the accuracy for each **_k_**\n",
    "\n",
    "Keep your experiment simple. (Hint: Use a loop.)\n",
    "\n",
    "Conclude your experiment with a markdown cell that asserts your proposed **_k_**, the accuracy of your classifier, and what leads you to choose this value of **_k_**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf908a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T21:40:09.885341Z",
     "iopub.status.busy": "2023-04-21T21:40:09.884446Z",
     "iopub.status.idle": "2023-04-21T21:40:10.763307Z",
     "shell.execute_reply": "2023-04-21T21:40:10.761474Z"
    },
    "papermill": {
     "duration": 0.897715,
     "end_time": "2023-04-21T21:40:10.766659",
     "exception": false,
     "start_time": "2023-04-21T21:40:09.868944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=0.9888888888888889\n",
      "k=2, accuracy=0.9805555555555555\n",
      "k=3, accuracy=0.9833333333333333\n",
      "k=4, accuracy=0.975\n",
      "k=5, accuracy=0.975\n",
      "k=6, accuracy=0.9722222222222222\n",
      "k=7, accuracy=0.975\n",
      "k=8, accuracy=0.975\n",
      "k=9, accuracy=0.975\n",
      "k=10, accuracy=0.9722222222222222\n",
      "k=11, accuracy=0.9722222222222222\n",
      "k=12, accuracy=0.9722222222222222\n",
      "k=13, accuracy=0.9722222222222222\n",
      "k=14, accuracy=0.9694444444444444\n",
      "k=15, accuracy=0.9694444444444444\n",
      "k=16, accuracy=0.9694444444444444\n",
      "k=17, accuracy=0.9666666666666667\n",
      "k=18, accuracy=0.9666666666666667\n",
      "k=19, accuracy=0.9611111111111111\n",
      "k=20, accuracy=0.9638888888888889\n"
     ]
    }
   ],
   "source": [
    "#  Knowledge Check 6 Code\n",
    "\n",
    "# Your experiment begins here. Start with the \"traditional\" initial k.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Iterate over k values and train/validate classifiers\n",
    "k_values = range(1, 21)\n",
    "accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    # Here I create a KNN classifier to use with different k values\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # use fit for training set\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # predicting labels for validation\n",
    "    y_predictions = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predictions)\n",
    "    \n",
    "    # compute accuracy\n",
    "    acc = accuracy_score(y_test, y_predictions)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    " \n",
    "    print(f\"k={k}, accuracy={acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43288e",
   "metadata": {
    "papermill": {
     "duration": 0.029458,
     "end_time": "2023-04-21T21:40:10.821086",
     "exception": false,
     "start_time": "2023-04-21T21:40:10.791628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  Knowledge Check 6\n",
    "\n",
    "Conclude your experiment with a brief assertion of your proposed **_k_**, the accuracy of your classifier, and what led you to choose this value of **_k_**.\n",
    "\n",
    "After trying mutiple values of k up to 20, I believe that when k=1, then it can be seen as the optimal value for the classifier with a 0.9888 on a validation set. Since a k of 1 means that each point is assigned to the class of its closest neighbor in its training set, then it can be considered an appropriate choice due to my provided small data set. Overall, the data seems consistent with a high accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30974cc",
   "metadata": {
    "papermill": {
     "duration": 0.014712,
     "end_time": "2023-04-21T21:40:10.859804",
     "exception": false,
     "start_time": "2023-04-21T21:40:10.845092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Congratulations on finishing an authentic machine learning workflow! While our dataset is of high quality, and the drama of preprocessing is abbreviated, we hope that this notebook enables you to see how we can use ML tools to carry out much of the machine learning process.\n",
    "\n",
    "Please wrap up this notebook with a brief narrative.\n",
    "\n",
    "###  Knowledge Check 7\n",
    "\n",
    "Imagine that a \"person on the street\" (or your twelve-year-old relative) asks you, \"What does it take for a computer to recognize handwritten characters that get scanned and turned into computable numbers?\" Rely on our journey through this notebook, infer and deduce what you can as necessary, but be mindful of your audience: please explain things in a manner befitting someone who knows nothing about these things.\n",
    "\n",
    "Conclude with your assertion about whether or not character recognition is an \"easy\" or \"very difficult\" machine learning problem, and whether or not this surprises you.\n",
    "\n",
    "*For a computer to recognize handwritten characters, I would say that it learns similarly to the way we (humans) do. For example, I can write letters and numbers on paper and scan them with my eyes to process what I wrote. However, the computer will scan handwritten characters as a bunch of dots and lines. What I want the computer to do is to read what it just scanned and understand it by processing it as well.*\n",
    "\n",
    "*For the computer to achieve this, the world would call it \"machine learning\". The computer will get a bunch of cool examples of handwritten letters and numbers and identify each one. It will learn how to recognize the different shapes and patterns that make up each letter or number. Once the computer has learned how to recognize the different shapes and patterns, it can use that knowledge to read new handwritten letters and numbers that it hasn't seen before.*\n",
    "\n",
    "*Think of it as a game. When approaching a difficult level with a fixed amount of obstacles (monsters, traps, loot), the more we recognize where every obstacle is, the higher the chance of us avoiding anything that would make us fail to complete that level. By the end of that level, we can recognize that specific monster, trap, and all the loot locations. The end result is that we can beat that level due to acquiring knowledge about it and mastering it.*\n",
    "\n",
    "*I would say that character recognition is a very difficult machine learning problem. Even with all the technology and techniques we have available, it can still be challenging to get a computer to recognize handwriting with high accuracy. However, with enough examples and careful training, we can get pretty good results, as we saw in our experiment.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.393224,
   "end_time": "2023-04-21T21:40:11.796587",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-21T21:39:55.403363",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
