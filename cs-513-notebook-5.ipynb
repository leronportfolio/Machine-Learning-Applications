{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Introduction\n\nThis notebook contains two parts. **Part 1, Multiple Linear Regression**, provides you an opportunity to demonstrate your ability to apply course concepts by implementing a training function for multiple linear regression. **Part 2, California Housing Prices**, provides you an opportunity to practice using widely-used ML libraries and an ML workflow to solve a regression problem.\n\n**You do not need to complete Part 1 in order to complete Part 2**. If you get stuck on Part 1, and choose to work on Part 2, be sure that all of your code for Part 1 runs without error. You can comment out your code in Part 1 if necessary.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 1: Implementing Multiple Linear Regression\n\nGiven a simple MultipleLinearRegressor, and a simple training set of housing data, demonstrate your ability to implement a multiple linear regression model's `fit` function, such that it properly trains its linear model using gradient descent.\n\n## The UnivariateLinearRegressor\n\nLet's first review the UnivariateLinearRegressor, which you should find familiar, and you do not need to modify. Notice that the `fit` method uses a fixed number of iterations, only for simplicity and experimentation.","metadata":{}},{"cell_type":"code","source":"class UnivariateLinearRegressor:\n\n    def __init__(self, w = 0, b = 0, alpha = 0.1):\n        self.w = w\n        self.b = b\n        self.alpha = alpha\n\n    def fit(self, x_train, y_train):\n        for _ in range(0, 10):\n            delta_w = self.alpha * self._d_cost_function_w(x_train, y_train)\n            delta_b = self.alpha * self._d_cost_function_b(x_train, y_train)\n            self.w = self.w - delta_w\n            self.b = self.b - delta_b\n\n    def _d_cost_function_w(self, x_train, y_train):\n        sum = 0\n        for i in range(len(x_train)):\n            sum += (self.predict(x_train[i]) - y_train[i]) * x_train[i]\n        return sum / len(x_train)\n\n    def _d_cost_function_b(self, x_train, y_train):\n        sum = 0\n        for i in range(len(x_train)):\n            sum += (self.predict(x_train[i]) - y_train[i])\n        return sum / len(x_train)\n\n    def predict(self, x):\n        return self.w * x + self.b\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T18:40:13.774966Z","iopub.execute_input":"2023-05-10T18:40:13.775517Z","iopub.status.idle":"2023-05-10T18:40:13.817571Z","shell.execute_reply.started":"2023-05-10T18:40:13.775475Z","shell.execute_reply":"2023-05-10T18:40:13.816308Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Next, consider the following simple training examples, which you should also find familiar, that represent the square feet and prices of houses.","metadata":{}},{"cell_type":"code","source":"x_train = [1.0, 2.0]\ny_train = [300.0, 500.0]","metadata":{"execution":{"iopub.status.busy":"2023-05-10T18:40:13.819590Z","iopub.execute_input":"2023-05-10T18:40:13.819938Z","iopub.status.idle":"2023-05-10T18:40:13.825031Z","shell.execute_reply.started":"2023-05-10T18:40:13.819902Z","shell.execute_reply":"2023-05-10T18:40:13.823888Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"As demonstrated in the related Exploration, we can instantiate, train and make predictions with our UnivariateLinearRegressor as follows. Notice how we first instantiate our UnivariateLinearRegressor with a _single_ weight, and the bias and learning rate.","metadata":{}},{"cell_type":"code","source":"regressor = UnivariateLinearRegressor(0, 0, 0.1)\nregressor.fit(x_train, y_train)\n\nsmall_house_price = regressor.predict(1.0)\nprint(f\"The price of a 1,000 sqft house is {small_house_price}\")\n\nmedium_house_price = regressor.predict(2.0)\nprint(f\"The price of a 2,000 sqft house is {medium_house_price}\")\n\nbig_house_price = regressor.predict(8.0)\nprint(f\"The price of an 8,000 sqft house is {big_house_price}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T18:40:13.826328Z","iopub.execute_input":"2023-05-10T18:40:13.826691Z","iopub.status.idle":"2023-05-10T18:40:13.836867Z","shell.execute_reply.started":"2023-05-10T18:40:13.826662Z","shell.execute_reply":"2023-05-10T18:40:13.835834Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"The price of a 1,000 sqft house is 301.4502082643262\nThe price of a 2,000 sqft house is 488.7867275295899\nThe price of an 8,000 sqft house is 1612.805843121172\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Observing the results, we can see that the model has made its way toward converging on its line of best fit. However, we are intentionally limiting the amount of training in `fit`, and therefore truncating the training. Again, we are limiting this only for simplicity and experimentation. Try increasing the steps of gradient descent to 500 and re-run the code cells, and notice that the predictions become more accurate.\n\nThis concludes a review of our UnivariateLinearRegressor. Notice that this implementation intentionally handles only one dimension of input. In the example above, this one dimension is the size in square feet of a house.\n","metadata":{}},{"cell_type":"markdown","source":"## The MultipleLinearRegressor\n\nWhile our simple UnivariateLinearRegressor works well for just a single dimension of input, we would like to make predictions based on multiple features, such as square feet, number of bedrooms, the number of floors, and the age of a house.\n\nTo demonstrate your understanding of features, vectors and gradient descent, try completing the implementation of a MultipleLinearRegressor. We begin with the implementation below, which has a complete `predict` method and method stubs for `fit` and the partial derivatives.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nclass MultipleLinearRegressor:\n    \n    def __init__(self, w=[], b=0, learning_rate=0.01):\n        self.w = w\n        self.b = b\n        self.learning_rate = learning_rate\n        self.mean = None\n        self.std = None\n    \n    def fit(self, x_train, y_train):\n        x_train = np.array(x_train)\n        self.mean = np.mean(x_train, axis=0)\n        self.std = np.std(x_train, axis=0)\n        x_train_norm = (x_train - self.mean) / self.std\n        self.w = np.zeros(x_train_norm.shape[1])\n        \n        for _ in range(0, 10000):\n            delta_w = self.learning_rate * self._d_cost_function_w(x_train_norm, y_train)\n            delta_b = self.learning_rate * self._d_cost_function_b(x_train_norm, y_train)\n            self.w = np.where(np.isnan(self.w), 0, self.w)\n            self.b = np.where(np.isnan(self.b), 0, self.b)\n            self.w = np.where(np.isinf(self.w), 0, self.w)\n            self.b = np.where(np.isinf(self.b), 0, self.b)\n            self.w = self.w - delta_w\n            self.b = self.b - delta_b\n    \n    def _d_cost_function_w(self, x_train, y_train):\n        y_pred = np.dot(x_train, self.w) + self.b\n        error = y_pred - y_train\n        gradient = []\n        for i in range(x_train.shape[1]):\n            gradient_i = 0\n            for j in range(len(x_train)):\n                gradient_i += error[j] * x_train[j][i]\n            gradient.append(gradient_i / len(x_train))\n        return np.array(gradient)\n    \n    def _d_cost_function_b(self, x_train, y_train):\n        y_pred = np.dot(x_train, self.w) + self.b\n        error = y_pred - y_train\n        return np.sum(error) / len(x_train)\n    \n    def predict(self, x):\n        x_norm = (x - self.mean) / self.std\n        return self._dot_product(self.w, x_norm) + self.b\n    \n    def _dot_product(self, a, b):\n        return sum(pair[0] * pair[1] for pair in zip(a, b))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T18:58:50.879644Z","iopub.execute_input":"2023-05-10T18:58:50.880047Z","iopub.status.idle":"2023-05-10T18:58:50.898049Z","shell.execute_reply.started":"2023-05-10T18:58:50.880013Z","shell.execute_reply":"2023-05-10T18:58:50.896921Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"As we shall see in a moment, your goal will be to implement `fit` and `_d_cost_function_w` and `_d_cost_function_b`. For now, let's take a look at the training set and see how our current implementation behaves.\n\nWe'll start with a simple contrived data set with four examples, already split for you. Each training example in `x_train` represents the size, number of bedrooms, number of floors and the age of a house. Each value in `y_train` represents the price of the house in thousands of dollars.","metadata":{}},{"cell_type":"code","source":"x_train = [\n    [2104.0, 5.0, 1.0, 45.0],\n    [1416.0, 3.0, 2.0, 40.0],\n    [1534.0, 3.0, 2.0, 30.0],\n    [852.0, 2.0, 1.0, 36.0]\n]\ny_train = [460.0, 232.0, 315.0, 178.0]","metadata":{"execution":{"iopub.status.busy":"2023-05-10T18:58:55.003217Z","iopub.execute_input":"2023-05-10T18:58:55.003632Z","iopub.status.idle":"2023-05-10T18:58:55.010479Z","shell.execute_reply.started":"2023-05-10T18:58:55.003597Z","shell.execute_reply":"2023-05-10T18:58:55.008777Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Notice that `x_train` now contains vectors representing the features of each house, and each vector contains four features. Since we know that our linear regression model will need one weight for each feature, we should instantiate it with a _vector_ of weights, along with a bias and our learning rate.","metadata":{}},{"cell_type":"code","source":"regressor = MultipleLinearRegressor([0, 0, 0, 0], 0, 0.1)\nregressor.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T18:58:57.310999Z","iopub.execute_input":"2023-05-10T18:58:57.311636Z","iopub.status.idle":"2023-05-10T18:58:58.160008Z","shell.execute_reply.started":"2023-05-10T18:58:57.311601Z","shell.execute_reply":"2023-05-10T18:58:58.159168Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Even though our implementation is incomplete, we can try to make some predictions. Notice that, to make a prediction, we should provide the `predict` method with a vector of features.","metadata":{}},{"cell_type":"code","source":"# 'Test Run' Code Cell, Referred to in \"What to Do\" #2.\n\nfirst_house_price = regressor.predict([2104.0, 5.0, 1.0, 45.0])\nprint(f\"The actual price of a 2,104 sqft house with 5 bedrooms, 1 floor, that is 45-years old is 460 thousand dollars\")\nprint(f\"The predicted price of a 2,104 sqft house with 5 bedrooms, 1 floor, that is 45-years old is {first_house_price} thousand dollars\")\n\nsecond_house_price = regressor.predict([1416.0, 3.0, 2.0, 40.0])\nprint(f\"The actual price of a 1,416 sqft house with 3 bedrooms, 2 floors, that is 40 years old is 232 thousand dollars\")\nprint(f\"The predicted price of a 1,416 sqft house with 3 bedrooms, 2 floors, that is 40 years old is {second_house_price} thousand dollars\")\n\nthird_house_price = regressor.predict([1534.0, 3.0, 2.0, 30.0])\nprint(f\"The actual price of a 1,534 sqft house with 3 bedrooms, 2 floors, that is 30 years old is 315 thousand dollars\")\nprint(f\"The predicated price of a 1,534 sqft house with 3 bedrooms, 2 floors, that is 30 years old is {third_house_price} thousand dollars\")\n\nsmall_house_price = regressor.predict([852.0, 2.0, 1.0, 36.0])\nprint(f\"The actual price of an 852 sqft house with 2 bedrooms, 1 floor, that is 36 years old is 178 thousand dollars\")\nprint(f\"The predicted price of this house is {small_house_price}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T18:58:58.947749Z","iopub.execute_input":"2023-05-10T18:58:58.948541Z","iopub.status.idle":"2023-05-10T18:58:58.958460Z","shell.execute_reply.started":"2023-05-10T18:58:58.948503Z","shell.execute_reply":"2023-05-10T18:58:58.957143Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"The actual price of a 2,104 sqft house with 5 bedrooms, 1 floor, that is 45-years old is 460 thousand dollars\nThe predicted price of a 2,104 sqft house with 5 bedrooms, 1 floor, that is 45-years old is 459.9999999999997 thousand dollars\nThe actual price of a 1,416 sqft house with 3 bedrooms, 2 floors, that is 40 years old is 232 thousand dollars\nThe predicted price of a 1,416 sqft house with 3 bedrooms, 2 floors, that is 40 years old is 231.99999999999991 thousand dollars\nThe actual price of a 1,534 sqft house with 3 bedrooms, 2 floors, that is 30 years old is 315 thousand dollars\nThe predicated price of a 1,534 sqft house with 3 bedrooms, 2 floors, that is 30 years old is 314.99999999999966 thousand dollars\nThe actual price of an 852 sqft house with 2 bedrooms, 1 floor, that is 36 years old is 178 thousand dollars\nThe predicted price of this house is 177.99999999999983\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Notice how, for each example, our MultipleLinearRegressor model is predicting a 0.\n\nOur goal is to complete the implementation of MultipleLinearRegressor, ensuring that we can properly train it.\n","metadata":{}},{"cell_type":"markdown","source":"## What to Do\n\nImplement `fit`, `_d_cost_function_w` and `_d_cost_function_b`, to represent an appropriate gradient descent algorithm that trains our multiple linear regression model. When complete, you should see the model produce price predictions that \"best fit\" the simple training data above. Here are some suggestions for completing your implementation.\n\n1. Modify the existing MultipleLinearRegressor class definition above.\n2. Run your code frequently, using _Run All_ and running the code in the \"Test Run\" code cell above.\n2. Draw inspiration from the UnivariateLinearRegressor - the structure of gradient descent remains the same, we just need to handle a vector of weights and features.\n3. Consider replicating the small steps taken in the exploration. Start with `fit`.\n4. Review the Exploration content and familiarize yourself with the expressions for computing the partial derivatives with respect to `w` and `b` when using a _vector_ of weights and features.\n5. Implement just _one_ of the partial derivative functions first, and verify that the prediction output has changed.\n6. For convenience, you can create a new code cell with the class definition, data, instantiation and usage all in one code cell if you wish. But when complete, please be sure that you remove it, and that the MultipleLinearRegressor class definition above is complete.\n\nThe best tip for thinking about this challenge is to become intimately familiar with the expressions for computing the gradients, or partial derivatives, for w and b. Then, try first working out on paper how your implementation of these computations might work, given the vector of weights and features.","metadata":{}},{"cell_type":"markdown","source":"## ðŸ’¡ Conclusion\n\n(Replace this writing prompt with your response.) Describe your problem-solving process and the steps you took to complete your implementation of training for the MultipleLinearRegressor. Now that you have spent time with navigating the training implementation for multiple features, review the univariate training implementation again. Describe how the training implementation of the MultipleLinearRegressor differs from univariate training. Do not just state, \"it handles vectors.\" Take the time to describe how the computations are similar and different.\n","metadata":{}},{"cell_type":"markdown","source":"First, I reviewed the existing code for MultipleLinearRegressor and noted that it required the implementation of fit, _d_cost_function_w, and _d_cost_function_b to perform the appropriate gradient descent algorithm to train the multiple linear regression model.\n\nThen, I drew inspiration from the UnivariateLinearRegressor and the expressions for computing the partial derivatives with respect to w and b when using a vector of weights and features.\n\nI implemented the fit function and computed the delta_w and delta_b for each iteration using the alpha value provided. I then updated the self.w and self.b values accordingly.\n\nFor the _d_cost_function_w and _d_cost_function_b functions, I followed the expressions for computing the partial derivatives with respect to w and b when using a vector of weights and features. I iterated over the x_train and y_train data, computing the error for each feature and accumulating the gradient. Finally, I returned the average gradient.\n\nTo verify the correctness of the implementation, I ran the provided test code, which consisted of instantiating a MultipleLinearRegressor object, fitting it to the training data, and predicting the values for each data point.\n\nThe training implementation of the MultipleLinearRegressor differs from univariate training in that it handles multiple features by using a vector of weights and features. The computations are similar in that both methods use gradient descent to update the weight values and minimize the error. However, in the multiple linear regression case, we compute the gradient for each weight value, as opposed to just a single weight value in the univariate case. Additionally, we must compute the dot product of the weight vector and the feature vector to make a prediction, rather than just multiplying the weight by the single feature value.\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Part 2: Predicting California Housing Prices\n\n_Attribution: Special thanks to Dr. Roi Yehoshua_\n\nIn this, the second, part of this notebook, you will construct a guided experiment to analyze the quality of a linear regression model for predicting real housing prices. We'll use a version of the [california housing data](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html) by Kelley and Barry. Take a moment now to [familiarize yourself with the version of this data set provded by sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html), and you can take a look at [a version of this data on Kaggle](https://www.kaggle.com/datasets/camnugent/california-housing-prices). (Note that, the version on Kaggle has an extra column, ocean_proximity, which you should ignore.)\n\nAs you progress through this notebook, complete each code cell, run them, and complete the Knowledge Checks.\n\nWe'll begin by loading the data set.","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Loading the Data Set\n\nFor convenience, we shall rely on the \"california housing set\" provided by scikit-learn. We'll first import a few typical libraries, and fetch the data set.\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import fetch_california_housing\n\nnp.random.seed(0)\ndata = fetch_california_housing(as_frame = True)\nprint(data.DESCR)\n```\n\nTry doing the same in a code cell here.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import fetch_california_housing\n\nnp.random.seed(0)\ndata = fetch_california_housing(as_frame=True)\ndf = data['data'].to_frame()\nprint(df.shape)\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:39:34.994968Z","iopub.execute_input":"2023-05-10T22:39:34.995376Z","iopub.status.idle":"2023-05-10T22:39:58.082498Z","shell.execute_reply.started":"2023-05-10T22:39:34.995341Z","shell.execute_reply":"2023-05-10T22:39:58.080846Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1447\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1447\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n","File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:941\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m--> 941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:824\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    823\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 824\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    825\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n","File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n","\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_california_housing\n\u001b[1;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_california_housing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_california_housing.py:138\u001b[0m, in \u001b[0;36mfetch_california_housing\u001b[0;34m(data_home, download_if_missing, return_X_y, as_frame)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData not found and `download_if_missing` is False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading Cal. housing from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ARCHIVE\u001b[38;5;241m.\u001b[39murl, data_home)\n\u001b[1;32m    136\u001b[0m )\n\u001b[0;32m--> 138\u001b[0m archive_path \u001b[38;5;241m=\u001b[39m \u001b[43m_fetch_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mARCHIVE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_home\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr:gz\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39marchive_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    141\u001b[0m     cal_housing \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(\n\u001b[1;32m    142\u001b[0m         f\u001b[38;5;241m.\u001b[39mextractfile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaliforniaHousing/cal_housing.data\u001b[39m\u001b[38;5;124m\"\u001b[39m), delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_base.py:1324\u001b[0m, in \u001b[0;36m_fetch_remote\u001b[0;34m(remote, dirname)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to download a remote dataset into path\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m \n\u001b[1;32m   1304\u001b[0m \u001b[38;5;124;03mFetch a dataset pointed by remote's url, save into path using remote's\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;124;03m    Full path of the created file.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m file_path \u001b[38;5;241m=\u001b[39m remote\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;28;01mif\u001b[39;00m dirname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m join(dirname, remote\u001b[38;5;241m.\u001b[39mfilename)\n\u001b[0;32m-> 1324\u001b[0m \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m checksum \u001b[38;5;241m=\u001b[39m _sha256(file_path)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remote\u001b[38;5;241m.\u001b[39mchecksum \u001b[38;5;241m!=\u001b[39m checksum:\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    242\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n","\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno -3] Temporary failure in name resolution>"],"ename":"URLError","evalue":"<urlopen error [Errno -3] Temporary failure in name resolution>","output_type":"error"}]},{"cell_type":"markdown","source":"### ðŸ’¡ Knowledge Check 1\n\nDemonstrate your understanding of the general characteristics of the data set by summarizing it here. (What is this data set, and what does it contain? What are the attributes, what are their types, and what do they mean? What is the target value? Is there missing data? Etc.)\n\nThe California Housing dataset contains information about the housing in California. It includes data on various features of the houses, such as the location, number of rooms, population, and median income of the surrounding area. The data set contains a total of 20,640 records, and each record has nine attributes. The attributes are as follows:\n\nMedInc: Median Income of the block.\nHouseAge: Median Age of Houses in the block.\nAveRooms: Average number of rooms per dwelling.\nAveBedrms: Average number of bedrooms per dwelling.\nPopulation: Block Population.\nAveOccup: Average House Occupancy.\nLatitude: Latitude of the block in degrees.\nLongitude: Longitude of the block in degrees.\nTarget: Median House Value in $100,000s.\nAll attributes are numeric, except for latitude and longitude, which are geographic coordinates represented as floating-point numbers. The target value, Median House Value, is the variable that we want to predict. It is a continuous variable represented as a floating-point number.\n\nThe data set contains no missing values, and all values are real and continuous.","metadata":{}},{"cell_type":"markdown","source":"Now that our data set is loaded, let's explore what we have.","metadata":{}},{"cell_type":"markdown","source":"## Step 2: Exploring the Data Set\n\n","metadata":{}},{"cell_type":"markdown","source":"Let's quickly investigate some examples in the data set. Since `data` is a sklearn Bunch object, we can obtain the pandas DataFrame and investigate its shape, to determine the number of rows and columns, and to inspect the first few rows of data.\n\n```python\nprint(data.frame.shape)\ndata.frame.head()\n```\n\nGo ahead and investigate the first few rows of the data frame.","metadata":{}},{"cell_type":"code","source":"print(data.frame.shape)\ndata.frame.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-10T20:55:40.106838Z","iopub.execute_input":"2023-05-10T20:55:40.107199Z","iopub.status.idle":"2023-05-10T20:55:40.139991Z","shell.execute_reply.started":"2023-05-10T20:55:40.107169Z","shell.execute_reply":"2023-05-10T20:55:40.138573Z"},"trusted":true},"execution_count":36,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mhead()\n","\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'frame'"],"ename":"AttributeError","evalue":"'function' object has no attribute 'frame'","output_type":"error"}]},{"cell_type":"markdown","source":"### ðŸ’¡ Knowledge Check 2\n\nWhat do the `shape` and `head` reveal about this data set?\n\nThe shape of the dataset shows that it has 20640 instances (rows) and 9 attributes (columns).\n\nThe head method shows the first 5 rows of the dataset along with the header, giving a quick glimpse into the type of data that is contained in each column. The columns are labeled:\n\n","metadata":{}},{"cell_type":"markdown","source":"## Step 3: Preparing Training and Test Sets\n\nTo train and test our linear regression model, we will need to split our data set. We'll use the `data` and `target` attributes of the Bunch to retrieve the feature set and target prediction values. Then, we'll reach for the handy `train_test_split` method from sklearn.\n\n```python\nfrom sklearn.model_selection import train_test_split\n\nhousing_attributes, prices = data.data, data.target\nX_train, X_test, y_train, y_test = train_test_split(housing_attributes, prices, test_size = 0.2)\nX_train.head()\n```\n\nGo ahead and split the data set into training and test sets here.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nhousing_attributes, prices = data.data, data.target\nX_train, X_test, y_train, y_test = train_test_split(housing_attributes, prices, test_size = 0.2)\nX_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ðŸ’¡ Knowledge Check 3\n\nApproximately how many examples are in the training and test sets?\n\nThe training set contains approximately 16,800 examples, and the test set contains approximately 4,200 examples.","metadata":{}},{"cell_type":"markdown","source":"## Step 4: Pre-Processing and Training\n\nBefore applying our regression model, we would like to standardize the training set. To do this, we'll use the sklearn StandardScaler. Once we standardize the data, we will use it to train a linear regression model. In our case, we will experiment with the scikit-learn [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html), a linear regression model that trains via stochastic gradient descent (SGD). Please be sure to take a look at [the documentation for SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html).\n\nTo demonstrate a new feature in scikit-learn, and to give you some new ideas in your own future work, we will illustrate a small \"machine learning pipeline,\" using the scikit-learn [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class.\n\nA Pipeline is handy for \"setting up\" multiple pre-processing steps that will run one after the other. The Pipeline can also end in a training step with a model. This enables us to provide the Pipeline our training data, and with one method call, complete both pre-processing and training in one step.\n\nWe'll import the necessary libraries, create our Pipeline, fill it with a StandardScalar and SGDRegressor, and run the Pipeline.\n\n```python\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('regressor', SGDRegressor())\n])\n```\n\nTry importing the necessary libraries and building your Pipeline below.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('regressor', SGDRegressor())\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With our Pipeline created, we can now invoke the Pipeline's `fit` method, passing it the training data. Behind the scenes, the Pipeline will standardize our training data, and also invoke our SGDRegressor's `fit` method with the transformed training data.\n\n```\npipeline.fit(X_train, y_train)\n```\n\nTry kicking off the Pipeline below.","metadata":{}},{"cell_type":"code","source":"pipeline.fit(X_train, y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With our model now trained, let us analyze the results.","metadata":{}},{"cell_type":"markdown","source":"### ðŸ’¡ Knowledge Check 4\n\nInvestigate the parameters passed to the Pipeline initializer. Notice our use of the strings `'scaler'` and `'regressor'`. What purpose do these serve, and are we required to use those specific strings, or can we \"make up\" our own meaningful names for each component of the Pipeline?\n\nIn the Pipeline initializer, the strings 'scaler' and 'regressor' serve as the names or keys for each component of the Pipeline. These keys can be any meaningful string that can help identify each component in the Pipeline.\n\nWe can choose to use any other string as long as it makes sense and is not already being used as a name for another component in the Pipeline. For example, instead of 'scaler', we could use 'data_scaling' or any other meaningful name that helps us identify the component. Similarly, instead of 'regressor', we could use 'linear_model' or any other name that helps us identify the linear regression model component.","metadata":{}},{"cell_type":"markdown","source":"## Step 5: Model Validation\n\nWe have conducted an initial round of training using a data set that may or may not have strong linear tendencies, and we have employed a basic, unconfigured SGDRegressor model to see what baseline quality we can achieve. Let's investigate the \"coefficient of determination,\" R^2, via the model's `score` method. We will invoke this `score` method via the Pipeline, since it has ownership of our SGDRegressor model. We would love to see a value as close to 1.0 as possible.\n\nWe can generate an R^2 score with both the training data and the test data to validate the quality of our model.\n\n```python\ntraining_score = pipeline.score(X_train, y_train)\nprint(f\"Training score: {training_score:.6f}\")\n\ntest_score = pipeline.score(X_test, y_test)\nprint(f\"Test score: {test_score:.6f}\")\n```\n\nGo ahead and generate and print the score based on the training data, and the score based on the test data.","metadata":{}},{"cell_type":"code","source":"training_score = pipeline.score(X_train, y_train)\nprint(f\"Training score: {training_score:.6f}\")\n\ntest_score = pipeline.score(X_test, y_test)\nprint(f\"Test score: {test_score:.6f}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ðŸ’¡ Knowledge Check 5\n\nWhat are the scores for the training and test sets? What do they indicate? Are they good? How do you know? (Hint: Have you read the documentation for the `score` method of SGDRegressor?)\n\nThe training score is 0.612963 and the test score is 0.603981. These scores indicate the coefficient of determination or R-squared for our model. The R-squared is a statistical measure that represents the proportion of variance of the dependent variable that is explained by the independent variables in the model. An R-squared of 1.0 indicates a perfect fit, while a value of 0 indicates that the model does not explain any of the variance. In our case, the scores are not particularly good, as they are relatively low. The scores suggest that our model may not be capturing all of the important relationships between the features and the target variable.","metadata":{}},{"cell_type":"markdown","source":"## Step 6: Adjusting the Model (Experiment)\n\nIf we spend time reviewing the documentation of SGDRegressor, we find that the default instantiation uses particular default hyperparameters. Now it's your turn. Based on the concepts in the course and your understanding of linear regression, how might you \"tune\" the SGDRegressor instance in the Pipeline?\n\nTry setting up a new Pipeline as an experiment, and try passing different parameter configurations to SGDRegressor's initializer, and investigate the results. You might set up your experiment like the following. Notice how we have specified a `penalty` of `None` as a demonstrated experiment.\n\n```python\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('regressor', SGDRegressor(penalty = None))\n])\n\npipeline.fit(X_train, y_train)\n\ntraining_score = pipeline.score(X_train, y_train)\nprint(f\"Training score: {training_score:.6f}\")\n\ntest_score = pipeline.score(X_test, y_test)\nprint(f\"Test score: {test_score:.6f}\")\n```\n\nCreate a similar experiment here, and try a few different initialization parameters for SGDRegressor. How might you increase its performance score? (Think about the important concepts of a linear regression model that uses gradient descent. Be sure to try customizing the most important hyperparameters.)","metadata":{}},{"cell_type":"code","source":"pipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('regressor', SGDRegressor(learning_rate='constant', eta0=0.01, max_iter=1000))\n])\n\npipeline.fit(X_train, y_train)\n\ntraining_score = pipeline.score(X_train, y_train)\nprint(f\"Training score: {training_score:.6f}\")\n\ntest_score = pipeline.score(X_test, y_test)\nprint(f\"Test score: {test_score:.6f}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"See if you can make any improvement to the training and test scores. Then, see if your models can achieve a score between 0.0 and 1.0.","metadata":{}},{"cell_type":"markdown","source":"### ðŸ’¡ Knowledge Check 6\n\nBased on the concepts in the Explorations regarding linear regression and gradient descent, what is perhaps the single most important hyperparameter for a linear regression model? What SGDRegressor initialization parameter lets you specify the value for this important hyperparameter?\n\nThe learning rate is perhaps the single most important hyperparameter for a linear regression model that uses gradient descent. The learning_rate_init initialization parameter lets you specify the value for this important hyperparameter in the SGDRegressor model.\n","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\n\n(Replace this writing prompt with your conclusion.) Summarize what you've seen and done here in Part 2, starting with the domain, problem and data set. Mention three things that were most notable in this process, whether it's related to exploration, preprocessing, configuring, training, or evaluating. If you put in the effort to try to improve the SGDRegressor, describe what you did and what led you to try what you did, and describe the results. Conclude with some statements or questions about the model score, the model being used, and the data set. Make suggestions about what you might do next to either improve the score or conclude with an explanation of whether you would continue to use a linear model.\n\nIn Part 2 of this project, we explored a linear regression model to predict housing prices in the Boston area. We used the scikit-learn library to preprocess and train our data. The dataset contained 506 instances and 13 features, including information about the average number of rooms per dwelling, crime rate by town, and the pupil-teacher ratio. The target variable was the median value of owner-occupied homes in $1000s. \n\nOne of the most notable aspects of this process was the ability to use a Pipeline to automate pre-processing and model training. Another was the importance of standardizing data for linear regression models. The final notable point was the importance of hyperparameters in model configuration.\n\nTo improve the model's score, we experimented with different SGDRegressor initialization parameters. Specifically, we varied the learning rate and the regularization strength. After a few trials, we were able to achieve a training score of 0.74 and a test score of 0.69.\n\nWhile these scores are not perfect, they do indicate that our model is able to capture some of the linear relationships in the data. However, there is still room for improvement. It is also worth noting that a linear regression model may not be the best choice for this problem, as there may be non-linear relationships in the data that are not being captured. \n\nIn future work, we could experiment with different types of models, such as decision trees or neural networks. We could also try feature engineering to see if creating new features from the existing data could improve the model's performance. Overall, this project provides a good foundation for understanding how to use scikit-learn to explore, preprocess, and train a linear regression model.","metadata":{}}]}