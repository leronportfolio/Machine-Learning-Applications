{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561f0f20",
   "metadata": {
    "papermill": {
     "duration": 0.007252,
     "end_time": "2023-05-20T22:10:09.317900",
     "exception": false,
     "start_time": "2023-05-20T22:10:09.310648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains two parts. **Part 1, Logistic Regression**, provides you an opportunity to demonstrate your ability to apply course concepts by implementing a training function for logistic regression. **Part 2, Classifying Fashion Items**, provides you an opportunity to practice using widely-used ML libraries and an ML workflow to analyze a classification problem using a logistic regression model.\n",
    "\n",
    "**You do not need to complete Part 1 in order to complete Part 2**. If you get stuck on Part 1, and choose to work on Part 2, be sure that all of your code for Part 1 runs without error. You can comment out your code in Part 1 if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4e49e",
   "metadata": {
    "papermill": {
     "duration": 0.00605,
     "end_time": "2023-05-20T22:10:09.330601",
     "exception": false,
     "start_time": "2023-05-20T22:10:09.324551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 1: Implementing Logistic Regression\n",
    "\n",
    "Given a nearly-complete LogisticRegressor, and a simple training set of tumor data, demonstrate your ability to implement a logistic regression model's `fit` function, such that it properly trains its model using gradient descent.\n",
    "\n",
    "## The LogisticRegressor\n",
    "\n",
    "Let's first review the LogisticRegressor, which you should find familiar. Notice that the `fit` method uses a fixed number of iterations, only for simplicity and experimentation, and is stubbed to do nothing. But, also notice that the comments in `fit` describe a training process using gradient descent.\n",
    "\n",
    "Run the code cell and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4f7ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T22:10:09.346081Z",
     "iopub.status.busy": "2023-05-20T22:10:09.345606Z",
     "iopub.status.idle": "2023-05-20T22:10:13.504775Z",
     "shell.execute_reply": "2023-05-20T22:10:13.503822Z"
    },
    "papermill": {
     "duration": 4.172044,
     "end_time": "2023-05-20T22:10:13.509350",
     "exception": false,
     "start_time": "2023-05-20T22:10:09.337306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [0.5, 1.5] is 0\n",
      "Prediction for [1, 1] is 0\n",
      "Prediction for [1.5, 0.5] is 0\n",
      "Prediction for [3, 0.5] is 1\n",
      "Prediction for [2, 2] is 1\n",
      "Prediction for [1, 2.5] is 1\n",
      "0.0016974661879524142\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class LogisticRegressor:\n",
    "\n",
    "    def __init__(self, w = 0, b = 0, alpha = 0.1):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, x_train, y_train, num_iterations=100000):\n",
    "        for _ in range(num_iterations):\n",
    "            delta_w = self._d_cost_function_w(x_train, y_train)\n",
    "            delta_b = self._d_cost_function_b(x_train, y_train)\n",
    "            \n",
    "            for i in range(len(self.w)):\n",
    "                self.w[i] -= self.alpha * delta_w[i]\n",
    "            self.b -= self.alpha * delta_b\n",
    "\n",
    "    def cost(self, x_examples, y_class_labels):\n",
    "        cost = 0\n",
    "        for i in range(len(x_examples)):\n",
    "            cost += self._loss(x_examples[i], y_class_labels[i])\n",
    "        return cost / len(x_examples)\n",
    "\n",
    "    def _loss(self, x, y):\n",
    "        z = self._dot_product(self.w, x) + self.b\n",
    "        return -y * math.log(self._sigmoid(z)) - (1 - y) * math.log(1- self._sigmoid(z))\n",
    "\n",
    "    def _d_cost_function_w(self, x_train, y_train):\n",
    "        delta_w = [0] * len(x_train[0])\n",
    "        for i in range(len(x_train)):\n",
    "            error = self._sigmoid(self._dot_product(self.w, x_train[i]) + self.b) - y_train[i]\n",
    "            for j in range(len(delta_w)):\n",
    "                delta_w[j] += error * x_train[i][j]\n",
    "        for i in range(len(delta_w)):\n",
    "            delta_w[i] = delta_w[i] / len(x_train)\n",
    "        return delta_w\n",
    "\n",
    "    def _d_cost_function_b(self, x_train, y_train):\n",
    "        delta_b = 0\n",
    "        for i in range(len(x_train)):\n",
    "            delta_b += self._sigmoid(self._dot_product(self.w, x_train[i]) + self.b) - y_train[i]\n",
    "        return delta_b / len(x_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self._sigmoid( self._dot_product(self.w, x) + self.b) >= 0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def _dot_product(self, a, b):\n",
    "        return sum(pair[0] * pair[1] for pair in zip(a, b))\n",
    "\n",
    "    def _sigmoid(self, exponent):\n",
    "        return 1 / (1 + math.exp(-exponent))\n",
    "\n",
    "\n",
    "\n",
    "x_train = [[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]]\n",
    "y_train = [0, 0, 0, 1, 1, 1]\n",
    "\n",
    "regressor = LogisticRegressor([0, 0], 0, 0.1)\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "for example in x_train:\n",
    "    print(f\"Prediction for {example} is {regressor.predict(example)}\")\n",
    "\n",
    "print(regressor.cost(x_train, y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd432b99",
   "metadata": {
    "papermill": {
     "duration": 0.006204,
     "end_time": "2023-05-20T22:10:13.525002",
     "exception": false,
     "start_time": "2023-05-20T22:10:13.518798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see from the output, our classifier is currently predicting only a 1, and its cost is about 0.69.\n",
    "\n",
    "## What to Do\n",
    "\n",
    "Your goal is to implement, in the code cell above, the `fit` function. When complete, you should see results identical to the output shown at the end of the *Exploration: Applying Logistic Regression*.\n",
    "\n",
    "1. Implement the `fit` function in the code cell above.\n",
    "2. Run the code cell frequently, and observe the output.\n",
    "3. When you believe your implementation is complete, increase the number of iterations. Compare your output to what we have seen in the corresponding Exploration.\n",
    "4. Rely on the functions that are already implemented for you, such as `_d_cost_function_b` and `_d_cost_function_w`.\n",
    "\n",
    "The best tip for thinking about this challenge is to become intimately familiar with the process of gradient descent, and recognizing what `_d_cost_function_b` and `_d_cost_function_w` return. **Use the comments in the `fit` function as a general guide, not a literal line-by-line translation into code.**\n",
    "\n",
    "You'll know your implementation is sound when the output of the code cell matches what we have seen in the *Exploration: Applying Logistic Regression*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6c0762",
   "metadata": {
    "papermill": {
     "duration": 0.006256,
     "end_time": "2023-05-20T22:10:13.537784",
     "exception": false,
     "start_time": "2023-05-20T22:10:13.531528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ’¡ Conclusion\n",
    "\n",
    "I took a look at the Logistic Regressor and made another code output to copy over. I looked back and forth and compared it to the exploration in this week's module. It took me a bit to understand the gradient descent optimization algoithm, but I managed to figure it out when diving deep into weights and bias in the logistic regression model. I implemented the fit method, where I write code using deltas for w and b. The deltas were able to compute the _d_cost_function_ and _d_cost_function_b successfully. When implementing weight and bias, I wrote code to calculate deltas using the _d_cost_function_w and _d_cost_function_b, which I used to update each weight element in w by subtracting the change times of alpha. I decided to also update the bias b by subtracting change times alpha as well. When I continiously modify and ran the implementation, the numbers of iterations match the exploration to the point where I feel like it's complete. Overall, the code iteratively performs gradient descent and is computing the gradients of the cost function, updating weights/bias based on computed gradients, and is constantly being repeated for this process by x amount of times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55032b",
   "metadata": {
    "papermill": {
     "duration": 0.006186,
     "end_time": "2023-05-20T22:10:13.550576",
     "exception": false,
     "start_time": "2023-05-20T22:10:13.544390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 2: Classifying Fashion Items\n",
    "\n",
    "In this, the second, part of this notebook, you will observe a non-annotated implementation of a machine learning process, and enhance it with descriptive markdown cells and additional code. Your goal is to narrate and improve an experiment that measures the performance of the [scikit-learn LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model for classifying images of fashion items. We'll use the popular [Fashion MNIST data set](https://github.com/zalandoresearch/fashion-mnist) by Xiao, Rasul, and Vollgraf. Take a moment now to [familiarize yourself with the version of this data set](), and also take a look at [a version of this data on Kaggle](https://www.kaggle.com/datasets/zalando-research/fashionmnist).\n",
    "\n",
    "Unlike prior notebooks, in which you are given either a guided framework of steps, or provided explicit code to try, in this notebook the code shall be your framework. Your goal is to break apart this one big code cell into a cohesive, multi-section, narrated Notebook, that guides the reader through the machine learning process. You have seen and practiced this in prior Notebooks, and you are encouraged to replicate the spirit of our past work here.\n",
    "\n",
    "In other words, below you have a bunch of code. Your goal is to:\n",
    "\n",
    "1. Narrate a machine learning process\n",
    "2. Explain what the code is doing, and add to it as necessary\n",
    "3. Experiment, tune the model, and discuss your results\n",
    "\n",
    "Your Notebook should consist of many sections, with each section representing a step in the machine learning process. The first section has been completed for you. Each section should start with a markdown cell containing a descriptive second-level header, and at least a few sentences that prepare the reader for what the purpose of the step is.\n",
    "\n",
    "Each section should consist of both prose, in markdown cells, and code cells. Almost every section should consist of multiple markdown and code cells. You should often add to the provided code. For example, if you have a section on exploring data, you should probably do more than just look at the `head` and `shape`.\n",
    "\n",
    "Your first step is to run the code block, and spend time with each line of code to discern how it reflects some unit of work in our machine learning process.\n",
    "\n",
    "In the end, demonstrate how you modify the experiment and/or tune the model to increase the accuracy of the model. (Spend time with the [official documentation of the data set](https://github.com/zalandoresearch/fashion-mnist). What is the human accuracy score? Can your model surpass it when validated with the complete training set?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97992188",
   "metadata": {
    "papermill": {
     "duration": 0.006342,
     "end_time": "2023-05-20T22:10:13.563373",
     "exception": false,
     "start_time": "2023-05-20T22:10:13.557031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Problem Statement\n",
    "\n",
    "Our goal is to automate the identification of images of ten different kinds of fashion items, from t-shirts to ankle boots. To do so, we will attempt to train a logistic regression model using a well-prepared data set of images of fashion items. Our goal is to tune our end-to-end machine learning process, and to tune our classification model, to see how accurately it may predict the correct class label of different fashion items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babc76c",
   "metadata": {
    "papermill": {
     "duration": 0.006354,
     "end_time": "2023-05-20T22:10:13.576273",
     "exception": false,
     "start_time": "2023-05-20T22:10:13.569919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Clothing used in Classification with Logistic Regression\n",
    "\n",
    "In this notebook, we will explore the task of classifying images of clothing items using logistic regression. The goal is to build a model that can accurately predict the class labels of different clothing items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086c09f",
   "metadata": {
    "papermill": {
     "duration": 0.006288,
     "end_time": "2023-05-20T22:10:13.589761",
     "exception": false,
     "start_time": "2023-05-20T22:10:13.583473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Dataset\n",
    "First, we will be using the Fashion MNIST dataset, a dataset to help learn about image classification . In this dataset, it contains grayscale images of various fashion items, including t-shirts/top, trousers, pullovers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots. Each image is a 28x28-pixel square of grayscale image.\n",
    "\n",
    "We will start by loading the libraries and dataset then examine its structure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14dafbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T22:10:13.605775Z",
     "iopub.status.busy": "2023-05-20T22:10:13.604611Z",
     "iopub.status.idle": "2023-05-20T22:10:23.566583Z",
     "shell.execute_reply": "2023-05-20T22:10:23.565517Z"
    },
    "papermill": {
     "duration": 9.973414,
     "end_time": "2023-05-20T22:10:23.569677",
     "exception": false,
     "start_time": "2023-05-20T22:10:13.596263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#warning of packages is a-ok!\n",
    "fashion_data = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_train.csv')\n",
    "fashion_data.shape\n",
    "fashion_data.head()\n",
    "fashion_test_set = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_test.csv')\n",
    "fashion_test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c628945",
   "metadata": {
    "papermill": {
     "duration": 0.006434,
     "end_time": "2023-05-20T22:10:23.583222",
     "exception": false,
     "start_time": "2023-05-20T22:10:23.576788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The dataset contains 60,000 training examples and consists of 785 columns. The first column is the label of the fashion item, and the remaining 784 columns is the pixel values image that we are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8370b8",
   "metadata": {
    "papermill": {
     "duration": 0.007096,
     "end_time": "2023-05-20T22:10:23.597053",
     "exception": false,
     "start_time": "2023-05-20T22:10:23.589957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2: Data Exploration\n",
    "\n",
    "Next, let's visualize some example images and their labels. What's happening here is a dictionary called labels is being defined from 0-9, which refers to class names. The function display_image is being defined, and takes on two parameters known as features, and numeric_label. The point of this function is to be responsible in displaying an image along with the correct class label. It will print out the class label based on the numeric_label in respect to the labels dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd633c4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T22:10:23.612690Z",
     "iopub.status.busy": "2023-05-20T22:10:23.612245Z",
     "iopub.status.idle": "2023-05-20T22:10:23.619939Z",
     "shell.execute_reply": "2023-05-20T22:10:23.618606Z"
    },
    "papermill": {
     "duration": 0.018776,
     "end_time": "2023-05-20T22:10:23.622706",
     "exception": false,
     "start_time": "2023-05-20T22:10:23.603930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = {\n",
    "    0: 'T-shirt / Top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot'\n",
    "}\n",
    "\n",
    "def display_image(features, numeric_label):\n",
    "    print(f\"Class: {labels[numeric_label]}\")\n",
    "    plt.imshow(features.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a42c053",
   "metadata": {
    "papermill": {
     "duration": 0.006344,
     "end_time": "2023-05-20T22:10:23.635807",
     "exception": false,
     "start_time": "2023-05-20T22:10:23.629463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 3: Data Preprocessing\n",
    "\n",
    "The third step is to preprocess the data. We will normalize the pixel values to a range of 0 to 1. This normalization step helps improve the convergence of the model when we are training it. What is going on in the code below is that we assigned X to be the value of fashion_data[fashion_data.columns[1:]], where fashion_data is a dataframe that contains fashion-related data, except the first column. Y on the other hand is assigned to fashion_data['label'], which means that it is a series column containing labels that is assigned to the fashion data.\n",
    "\n",
    "X.head, and Y.head is being called, which shows the first few rows of X and Y. The display image is also being called three times with different aspects of the arguments. What it does is it takes the pixel values of an image from X using the loc[] accessor and take the label from Y. We can see that X is dividing it by 255, which means that the pixels value in X is being normalized. The values that are dividing by 255 are pixel values between 0 and 1. X.head will be called, which will show the normalized values of X after the normalization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13e7eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-20T22:10:23.651082Z",
     "iopub.status.busy": "2023-05-20T22:10:23.650670Z",
     "iopub.status.idle": "2023-05-20T22:10:24.335013Z",
     "shell.execute_reply": "2023-05-20T22:10:24.333626Z"
    },
    "papermill": {
     "duration": 0.695263,
     "end_time": "2023-05-20T22:10:24.337732",
     "exception": false,
     "start_time": "2023-05-20T22:10:23.642469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Pullover\n",
      "Class: T-shirt / Top\n",
      "Class: Sneaker\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3    pixel4    pixel5  pixel6  pixel7    pixel8  \\\n",
       "0     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "1     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "2     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.019608   \n",
       "3     0.0     0.0     0.0  0.003922  0.007843     0.0     0.0  0.000000   \n",
       "4     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "\n",
       "   pixel9  pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0     0.0      0.0  ...  0.000000       0.0       0.0  0.000000  0.000000   \n",
       "1     0.0      0.0  ...  0.000000       0.0       0.0  0.000000  0.000000   \n",
       "2     0.0      0.0  ...  0.000000       0.0       0.0  0.117647  0.168627   \n",
       "3     0.0      0.0  ...  0.011765       0.0       0.0  0.000000  0.000000   \n",
       "4     0.0      0.0  ...  0.000000       0.0       0.0  0.000000  0.000000   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0  0.000000       0.0       0.0       0.0       0.0  \n",
       "1  0.000000       0.0       0.0       0.0       0.0  \n",
       "2  0.000000       0.0       0.0       0.0       0.0  \n",
       "3  0.003922       0.0       0.0       0.0       0.0  \n",
       "4  0.000000       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = fashion_data[fashion_data.columns[1:]]\n",
    "Y = fashion_data['label']\n",
    "X.head()\n",
    "Y.head()\n",
    "display_image(X.loc[0].values, Y.loc[0])\n",
    "display_image(X.loc[10].values, Y.loc[10])\n",
    "display_image(X.loc[59999].values, Y.loc[59999])\n",
    "X = X / 255\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e75d3fe",
   "metadata": {
    "papermill": {
     "duration": 0.007201,
     "end_time": "2023-05-20T22:10:24.352535",
     "exception": false,
     "start_time": "2023-05-20T22:10:24.345334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, X represents the features (pixel values) of the images, and Y represents the corresponding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4989924",
   "metadata": {
    "papermill": {
     "duration": 0.007131,
     "end_time": "2023-05-20T22:10:24.367131",
     "exception": false,
     "start_time": "2023-05-20T22:10:24.360000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 4: Model Training and Evaluation\n",
    "\n",
    "To train and evaluate our logistic regression model, we will split the dataset into training and testing sets. The training set will be used to train the model, and the testing set will be used to evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494994c",
   "metadata": {
    "papermill": {
     "duration": 0.007166,
     "end_time": "2023-05-20T22:10:24.381852",
     "exception": false,
     "start_time": "2023-05-20T22:10:24.374686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Results and Analysis\n",
    "\n",
    "Below written code consist of the variables x_train, x_test, y_train, and y_test, which are assigned based on the outcome of utilizing the train_test_split function. This function effectively divides the X dataset and its corresponding labels Y into separate training and testing sets. We made the test size 20%. Next, we inspect the shape of x_train, y_train, x_test, and y_test by employing the shape attribute. This provides us with valuable insights into the dimensions of each array, enabling us to understand the number of rows and columns present. After that, the code enters a loop, iterating through a predefined list of values [1, 10, 50]. Once the model is trained, we move on to the pivotal phase of prediction and evaluation. Predictions are made on the x_test data using the predict method, allowing us to compare the predicted values (y_pred) against the actual labels (y_test).  Accuracy represents the proportion of correctly predicted labels to the total number of samples and the accuracy_count is the specific count of correctly predicted labels. Precision on the other hand is recall as derived weighted averages.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5900c21",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-20T22:10:24.398983Z",
     "iopub.status.busy": "2023-05-20T22:10:24.398081Z",
     "iopub.status.idle": "2023-05-20T22:10:39.852955Z",
     "shell.execute_reply": "2023-05-20T22:10:39.851370Z"
    },
    "papermill": {
     "duration": 15.468211,
     "end_time": "2023-05-20T22:10:39.857525",
     "exception": false,
     "start_time": "2023-05-20T22:10:24.389314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test records:\t 12000\n",
      "Accuracy count:\t\t 3699\n",
      "Acccuracy:\t\t 0.30825\n",
      "Precision:\t\t 0.5242862033967779\n",
      "Recall:\t\t\t 0.30825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test records:\t 12000\n",
      "Accuracy count:\t\t 8762\n",
      "Acccuracy:\t\t 0.7301666666666666\n",
      "Precision:\t\t 0.7239854018686158\n",
      "Recall:\t\t\t 0.7301666666666666\n",
      "Number of test records:\t 12000\n",
      "Accuracy count:\t\t 10150\n",
      "Acccuracy:\t\t 0.8458333333333333\n",
      "Precision:\t\t 0.8448312863097965\n",
      "Recall:\t\t\t 0.8458333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "x_train.shape\n",
    "y_train.shape\n",
    "x_test.shape\n",
    "y_test.shape\n",
    "\n",
    "for iterations in [1, 10, 50]:\n",
    "    logistic_model = LogisticRegression(max_iter = iterations)\n",
    "    logistic_model.fit(x_train, y_train)\n",
    "    y_pred = logistic_model.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred, normalize = True)\n",
    "    accuracy_count = accuracy_score(y_test, y_pred, normalize = False)\n",
    "    precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "    print(\"Number of test records:\\t\", len(y_test))\n",
    "    print(\"Accuracy count:\\t\\t\", accuracy_count)\n",
    "    print(\"Acccuracy:\\t\\t\", accuracy)\n",
    "    print(\"Precision:\\t\\t\", precision)\n",
    "    print(\"Recall:\\t\\t\\t\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc6c24e",
   "metadata": {
    "papermill": {
     "duration": 0.016065,
     "end_time": "2023-05-20T22:10:39.890418",
     "exception": false,
     "start_time": "2023-05-20T22:10:39.874353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To sum everything up in this code chunk, we iterate over different numbers of iterations for the logistic regression model. We train the model on the training set and then predict the labels for the testing set. We then computed various evaluation metrics, including accuracy, precision, and recall, to see how the performance of the model performs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a26fda",
   "metadata": {
    "papermill": {
     "duration": 0.016694,
     "end_time": "2023-05-20T22:10:39.923664",
     "exception": false,
     "start_time": "2023-05-20T22:10:39.906970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we dived into classification with logistic regression on clothes. We prepared the data, trained a logistic regression model, and evaluated its performance using various metrics. By experimenting with different numbers of iterations, we observed how the model's accuracy changed. If we were to improve the model, we can investigate additional techniques and hyperparameter settings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 45.67632,
   "end_time": "2023-05-20T22:10:41.060844",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-20T22:09:55.384524",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
